{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading the content\n",
    "df = pd.read_json(\"https://raw.githubusercontent.com/selva86/datasets/master/newsgroups.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading the stemmed data with pickle\n",
    "stem_data = pickle.load( open( \"stemmed_data.p\", \"rb\" )) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>preprocessed</th>\n",
       "      <th>target</th>\n",
       "      <th>target_names</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>car wonder enlighten car saw dai door sport ca...</td>\n",
       "      <td>7</td>\n",
       "      <td>rec.autos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>clock poll final final clock report acceler cl...</td>\n",
       "      <td>4</td>\n",
       "      <td>comp.sys.mac.hardware</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>question folk mac plu final gave ghost weekend...</td>\n",
       "      <td>4</td>\n",
       "      <td>comp.sys.mac.hardware</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>weitek robert kyanko rob rjck uucp wrote abrax...</td>\n",
       "      <td>1</td>\n",
       "      <td>comp.graphics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>shuttl launch question articl cowcb world std ...</td>\n",
       "      <td>14</td>\n",
       "      <td>sci.space</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        preprocessed  target  \\\n",
       "0  car wonder enlighten car saw dai door sport ca...       7   \n",
       "1  clock poll final final clock report acceler cl...       4   \n",
       "2  question folk mac plu final gave ghost weekend...       4   \n",
       "3  weitek robert kyanko rob rjck uucp wrote abrax...       1   \n",
       "4  shuttl launch question articl cowcb world std ...      14   \n",
       "\n",
       "            target_names  \n",
       "0              rec.autos  \n",
       "1  comp.sys.mac.hardware  \n",
       "2  comp.sys.mac.hardware  \n",
       "3          comp.graphics  \n",
       "4              sci.space  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Mounting a DF\n",
    "corpus_annot = pd.DataFrame({\"preprocessed\":stem_data,\"target\":df['target'],\"target_names\":df['target_names']})\n",
    "corpus_annot.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeoAAAEICAYAAACQ4bezAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nOzdd5hV1dn38e9P1NgQbOG1ExtELCgjVhQNMcbeSWI0atSHPFEsryY+arDEGDFGEzVRia9ij7ERuyhSFAEpAgPWR9QUjRVBxIJwv3+s+zCbM/ucOWeYBnN/rmsuzuy99lpr7/FynbXLb8vMCCGEEELbtEJrdyCEEEIIpcVAHUIIIbRhMVCHEEIIbVgM1CGEEEIbFgN1CCGE0IbFQB1CCCG0YTFQhxBCCG1YDNQhLCckzcv8LJL0eeb3Y1q4L6tIMkkblSkzwMucVrT8Q0m7NH8vS8v0/7PMMfxPa/YptF8xUIewnDCzNQo/wD+AgzLL7qymLkkrNk8v6/kYOF/Sai3UXrW6ZY7h/8kr0ILHKrRTMVCH0E5I2l3SBElzJL0j6erCIJOZQf5M0hvADF9+gKTXJX0i6Q+Sxkv6cabO/5L0qqSPJT0qaUNfNcb/fdVno4eW6NaLQC1wWt7KCvs8QNIbkuZKukBSN0kv+DZ3ZgdSSYdJmu7786ykrRtxHPeT9L+SfiXpPeD6huqW1FvSNEmfSrpD0gOSLvB1AyQ9nSm7xNkISav6sf+npP9IulbSN4r6cp6kDyT9O3v2RNLqkq7xbedIGi1pRUkjJJ1ctF+vSdqv2uMRml8M1CG0HwuAU4G1gT7AQcBJRWUOBHoBO0j6P8A9wJnAesA7vg4AST8AzvB6upAG3Tt89Z7+b2FGOqxMvy4AfiFpzUb2+TvA9sBewIXAtcBRwLeA3sAR3t9dgD8DJwDrALcDwxo5I+4KrARsDAwsV7ekVYBhwI2+H48DB1fR1tXARsC2QDdgK+DczPpNAQEbkI7VDZLW8HXXAN2BnbztCwADbgWyX7h2BtYEnqqiX6GlmFn8xE/8LGc/wFtAvwbKnAvc7Z9XIf0PfLfM+lOAkZnfVwDeB37sv48EjsmsX4k0sHbJ1LdRmfYHAE/754eAi/3zh8AuVfS5V2b9TOD0zO9/Ai73z7cA5xfV9zawc047hbrnAJ/4zxW+bj/gM2ClTPmSdQP7Am8WrZsCXFB8HIra3ghYEfgK2DCzfm/g5Uxf5gArZNbPBXpm/h7dcvZvdS+3if9+HXBVa/93Gz/5P3FtJYR2wk/F/h7YEViVNAiMLSr2z8znDbK/m9kiSf/OrN+UNHv7U2bZ16QBZk6V3fsVMFrSNY3o83uZz5/n/F6YXW4KHC3pnMz6lYENKa2Hmf0rZ/l/zGxB5vdyda8JFNfxdpk2szYgDbgzJRWWiXScCz4ws0WZ3+eT9nl90vGaVVypmX0m6QHgGElXAv1JXyhCGxSnvkNoP/5CmsltbmZrApeQ/qeflX2d3rukQRcASSuw5KD2T+B4M+uc+VnVzCYX1dMgM5sGPAH8shF9rtQ/gUFF/V3NzB5oRF3F+1eu7iWOo9sk8/kzIHszXfamtXdJg/LmmXo7mdk6FfSxsO1mJdYXTn/vB7xnZi9WUGdoBTFQh9B+dATmmNk8ST2Akxso/xCws6T9/TruWcBamfU3ABdI6gYgaS1JRwCY2ZekWXWpQSLPhaTTwNlBq9o+lzMEOE1SjZI1JB3cRHecl6t7DLCK3zS2oqQfAttltp1Kuiegh5cfVFjhs/abgT9KWtfr3ljSdxvqkG97m2/bRVIHSXtI6uBFRpFm3r/xcqGNioE6hPbjTOAkSfNI127vKVfYzN4Ffki6IelD0qywFvjS199Nurb5gKS5pAEnO4AMAu71u6AbvHnKzF4F7iOd4m5UnxuofywwkHRT1yfAa8CPqHL2X23dZvY5cBjw38Bs4ADg4cy2tcAVwLPAK6QBNOsM0o18k0hffp4AtqiwawOBN0g3+n0E/Bo/I2FmRrrprQdwVxW7G1qY0t8qhBDK81n1f0jPZ49r7f4syyT9FZhhZpe2cj9OAY42s36t2Y9QXsyoQwglSfq+pE7+iNGFpBuVJrdyt0ITkLQ68DPSafvQhsVAHUIoZ0/gTdJjWd8BDjOzr1q3S2Fp+aWI94H/JV1uCG1YnPoOIYQQ2rCYUYcQQghtWASehCa37rrrWteuXVu7GyGEsEyZPHnyh2a2XvHyGKhDk+vatSuTJk1q7W6EEMIyRVJuYl2c+g4hhBDasJhRhyY3+dNP0ahRrd2NENok69u3tbsQljHL/YxaUmdJ/11BuXn+b19JjzRh+29JWtc/P19B+Zsa847cxpJ0iaQIOwghhDaqPcyoO5Oi+/7cHJVL6mBmCyspa2a7VVCm+F27zcrMBjVcKoQQQmtZ7mfUwOXA5pKmSrpa0ghJUyTVSjqk3IaSdpL0oqTNipb3lTRS0l2k7GMk/VjSC97OjZng++x2hVn7CpL+LGmmpEckPSbpSF83SlKNf/6h93OGpMHZeiT9RtI0SeMldclp63hJwyQ9LOlNSadKOsv3Z7yktb3c0Ezbl0t6SdJ0f/UdHub/oLc1TVKDXzZCCCE0nfYwUJ8LvGFmPYFzSMlKO5Jevv57ZV7ymuUD0g3AIWZW732uQG/Si+K3lvRt0vtcd/d2FgLHlOnT4UBXYFvgJGDXnPY3AAYD+5BeAr+TpEN99erAeDPbnvRmnlJvFNqG9GKA3qQ35Mw3sx2AccBxRe2tTXpxQA8z2w4oZBBfA4z2tnYEZuY1JOkUSZMkTWJOta8iDiGEUEp7GKizBFwmaTrwNOnduvVmo8C3Sfm3B5nZP0rU9YKZvemfvwP0AiZKmuq/l3u93x7AvWa2yMz+A4zMKbMTMMrMPjCzr4E7SXGOAF8Bhevok0mDfp6RZvapmX1AeutO4Y09tTnbzAW+AG6SdDgp0xnSF4XrAcxsoZnljsJmNsTMasyshk6dSnQnhBBCtdrDNeqsY4D1gF5mtkDSW8AqOeXe9eU7kF4vl+ezzGcBt5rZ/1TYj0pefF+uzAKry35dSOm/45eZz4syvy8q3sbMvpbUm/Ql4wfAqaRBOoQQQitqDzPqT0kvnwfoBLzvg/TewKYltvmE9M7YyyT1raCNEcCRkr4J6TSypFJ1AzwHHOHXqrsAeW1MAPbyl8V3IL0XeHQFfWkUSWsAnczsMdL7b3v6qhGkN+zgL55fs7n6EEIIob7lfqA2s4+AsZJmkAafGkmTSLPrV8ps9x5wEPAnSTtLqpF0U4myLwEXAMP9tPpTwPplunU/8C9gBulF8xNIp6azdb4L/A/ptPg0YIqZ/b3cvko6WNIl5cqU0RF4xPs/GjjTl58O7C2plnSavUcj6w8hhNAI8fasViJpDTObJ2kd4AXSjWj/ae1+NYWamhqLCNEQQqiOpMlmVlO8vL1do25LHpHUGVgZ+PXyMkiHEEJoWjFQtxIz69vafWguESEawvIp4k9bx3J/jbqgtaNEM/XXixSV1FXSjzJlaiRd09Rtl+hPi0aWhhBCqE67GaipixJtMzKRol1JwSSF5ZPMbGAL9eEkvxkuhBBCG9SeBurmihId4xGbL0m6QdIKvi43/rNo+3mZvvXxvp2Znc1LWkPSLV7XdElH+GNSQ73uWkln5tR9kaRbJQ33Wfzhkq7w8k9IWsnLjfIZfG6dkraQ9LTHh06RtHmVxz2EEMJSaE/XqM8FtjGznpJWBFYzs7l+Gnq8pIcs5xZ4jxK9lhQlmpdS1hvYGngbeAI43E9pDyallc0mPbZ1qJkNK9O3s83sQG+zb2bdr4A5Zratr1uL9JjZhma2jS/rXKLezUlRqVuTYkOPMLNfSHqQ9Jx4tj+l6rwTuNzMHpS0CiW+3Ek6BTgFgC55YW8hhBAaoz3NqLOaOkp0lr9B625SPGi5+M9q9QP+VPjFzGYDs4DNJF0raT9S/Geex81sASkytAPpiwTkR4jWq1NSR9Lg/aC3/YWZzSdHRIiGEELzaK8DdTZKtCfwHqWjRL8gRYmWUjwLNyqLCK2UitvwwXp7YBTwcyA3iAWPDDWzRSwZO5oXIZpXZ1PuRwghhEZoTwN1c0WJ9pb0Lb823Z8UD1pt/Ge2b8WGk3K3gXTq20/Xr2Bm95NOje9Ypu6K5NVpZnOBf8nf2iXpG5JWW9q2QgghVK7dXKM2s48kFaJEJwLdPUp0Kg1EiUo6CHhc0omkl2AMMLOTvMg40s1g25JeOfmgmS2SVIj/FPBYA/Gf04GvJU0DhgIvZtZdSooxneFtXwy8AdxSuHGNFDWKpAHe5xsqOihL2jCvTuBY4EaPJl0AHEU6TV5Sr44dmRTPW4YQQpOICNGl4LPsxTeBhSQiREMIoXoRIRpaTCSThdA+RXJZ84iBeimY2SjSzVchhBBCs2hPN5O1CYUI0UojTXO2PyN7Q1cmNKXS7Q+WdG617YYQQmgdMVC3nsZGmp4BNPrOazN7yMwub+z2IYQQWlYM1M1I0jBJkyXN9OSurGyk6e9ytr1e0iTf9mJfNhDYABgpaWSm7G884nO8pC6+bD1J90ua6D+7+/LjJV3nn4/yyNBpksZk1g+T9LCkNyWdKukspQjV8ZLWbo5jFUIIIV8M1M3rRDPrBdQAAyWtk1l3LvCGmfU0s3Nytj3f7/7bjvRM9nZmdg3wDrC3me3t5VYHxpvZ9qTHw0725X8ErjaznYAjyA9FGQR8z7c9OLN8G9JLQnoDvwHmm9kOpEfRjsvbUUmn+BeLScyZU/aghBBCqFzcTNa8Bko6zD9vDGxZxbZH+yx8RWB9Ul739JxyXwGF13FOBr7rn/sBW0uLw8XW9EjQrLHAUEl/Ax7ILB9pZp8Cn0qaAzzsy2tJXxzqMbMhpLhV1K1bPPMXQghNJAbqZuLPWPcDdjWz+ZJGkR9Tmrftt4CzgZ3MbLakoWW2zUaDLqTub7qCt/15Ud2LP5vZAEk7k9LXpkrq6au+zGyyKPN7vejREEIIzStOfTefTsBsH6S7A7sUrS8XG7om8Bkwx685f7/C7bKKo0d7FheQtLmZTTCzQcCHpFl/CCGENiRmR83nCWCAv6HrVWB8dmVRpOnjZnaOpKl+zXqapBeBmaS4zrGZTYeQ4kzfzVynzjOQFD06nfR3HgMMKCrzO0lbkmJORwDTSK+7XCoRIRpCCE0nIkRDk4sI0RBCqF5EiIYWExGiIYTWtjzFmbaLa9SVpoAVUr4k9ZX0SEPlG9GPt/x1kkh63v/tKulHmTI1kq5p6rZDCCEsm9rFQE3jU8CajZnt5h+7kp5ZLiyfZGYDW6VTIYQQ2pz2MlBnU8CuljRC0hRJtZIOKbehpJ08lWuzouV9JY2R9KCklyTdUHiXs6Qfet0zJA0uUW8ho/tyoI/37czsbF7SGpJu8bqmSzpCUgdJQ73uWkln5tS9nqSnfB9vlPS254t39ZvXCuXOlnSRfx4labCkFyS9JqmPL+/hy6Z6H6p5FjyEEMJSai/XqM8FtjGznpJWBFYzs7l+Gnq8pIcs5646SbsB1wKHmNk/curtTQoieZt0l/fhfkp7MNALmA0Ml3SomQ0r07fF77T2568LfgXMMbNtfd1apLuyNzSzbXxZ55w6LwSeMbPfStoPKI4vLWVFM+staX+vox/pTvE/mtmdklYGOuRt6OEsqZ0uXSpsLoQQQkPay4w6S8Bl/tjS08CGQN7I8m3So1AHlRikAV4ws1lmthC4G9gD2AkYZWYfmNnXwJ3Ano3saz/gT4VfzGw26XGtzSRd64Pw3Jzt9gD+6ts8QfrCUIlCOtlk0il5SLGh50n6JbBpcYBKpm9DzKzGzGro1KnC5kIIITSkPQ7UxwDrAb3MrCfwHvmpX+8CXwA7lKmreBZupC8CTUXFbfhgvT3pPdg/Jz/Du1QfvmbJv3nxfhcSyBYnnJnZXaQc8M+BJyXtU3n3QwghLK32MlBn07w6Ae+b2QJJewObltjmE1K05mVFp6Ozekv6ll+b7g88B0wgvURjXUkdgB8CoyvsW7HidLG1/HT9CmZ2P+nU+I452z0HHO3b7Aus5cvfA74paR1J3wAOLNOvQpubAbP8hSAPUSLrO4QQQvNoFwO1mX0EFFLAegI1kiaRZtevlNnuPeAgUsLXzv7oVHYGO450M9gM4E3gQTN7F/gfYCQp6WuKmf29TPemA18rvWqy+MawS4G1/MaxacDepFP1oyRNBYZ6W0gaIKmQPHYxsK+kKaT40XeBT81sAXAJ6cvEI+X2PaM/MMPb6w7cVsE2IYQQmkgkkzWSz7IX3wTWlvhseaGZfS1pV+B6P83fIiKZLIQQqhfJZO3LJsDf/JT8V9S9ozqEEMIyJmbUocmpWzfjxhtbuxshhNCgthQ1WmpGvUxco44I0JL9uUnS1jnLj5d0XRO2U9HxDyGE0PSWiYGaiAAt1YeTzOylFmiqzR3/EEJoL5aVgbq9RYBeJOlWScN9Fn+4pCu8/BOSVvJyoyTV+OcTPPpzNLB7pq71JN0vaaL/7O7Le0t63o/N85K6+fK8yNDs8f9dw3+uEEIITWVZuZmsvUWAAmxOehxra9JjYEeY2S8kPUh6vntxfyStT3okqxcwh/Ro2Iu++o/A1Wb2nKRNgCdJqWuvAHv6neH9gMuAI8iPDF18/Ev0NSJEQwihmSwrA3VWIQJ0T2ARdRGg/ykqV4gA3dfM3ilR1wtmNgtAUiECdAEeAerLCxGgpQbqcvoBPyj8YmazJS2OAAUeJYWa5HncQ1lqSYPlE768lrp4z4Kdi/p8D7BVpg9bS4vDytaU1JEU/HKrz5gNWMnXjwPOl7QR8ICZvZ7ZtiQzG0I63ulmshBCCE1iWTn1ndUeIkDB4zzNbBGwIHPGYBH5X7BKDY4rALuaWU//2dDMPgV+DYz0mf1B+DGMyNAQQmhblpWBur1FgFZrAtBXKRp0JeCoMn0onL7uBPzbPx+fWZ8XGVpuH0MIITSjZeLUt5l9JKkQAToR6K4UATqVBiJAJR0EPC7pRNLLJgaY2UlepBABui0whhQBukhSIQJUwGOVRoCSIj1fzKy7lBQ/OsPbvhh4A7ilcOMamQhQ7/MNFR2UJffzXaX3So8jnUmYQt3rKAd6H6aT/t5jSNehryCd+j4LeCZTXX/gx5IWkC4nXGJmH2eO/+Nmdk65/vTq2JFJbejZxBBCWJa128ATteEI0GVdRIiGEEL1tCwHnoQQQgjt1TJx6rs5mNko0g1doYlN/vRTNGpUa3cjhBCWSluJF40ZdStR08d8dvVryCGEEJYjMVAvo/yO9OasX5kb3kIIIbSSZvkfsaTjPH5ymqTbJW2qFPs53f/dxMsNlXS9pJGSZknaS9LNkl6WNDRT3zxJv1eKDR0hab2cNvfyiMupHovZ0ds+JFPmTkkHl4jJLK7vLUmXSRonaZKkHSU9KemNwh3aShGhuXGmxcegxKHaQCkS9HVJV2S2vd7bnCnp4qI+DZL0HHCUpF5e/zjSM9mFco9J2s4/vyhpkH/+taSTSvXbZ+UvS/oz6c7xjSXt68dgiqR7Ja1R/q8fQgihKTX5QC2pB3A+sI+ZbQ+cDlwH3GZm2wF3Atm3S60F7AOcCTwMXA30ALbNPPO7OjDFzHYkPdN8YU7TZwM/9xCUPqTAjpuAE7xfnYDdgMeoi8nsCdQA/yqxO/80s12BZ0mPXh0J7AJc4uu/AA7zfu0N/N5nonnHIE9P0uNQ2wL9JW3sy8/3O/+2Iz3TvV1mmy/MbA8z+ytwCzDQ+5g1hpQ/vibwNXXZ33v4vuT228t0I/2tdgA+Ay4A+nnZScBZeTsi6RT/cjGJOXNK7G4IIYRqNceMeh/gPjP7EMDMPgZ2Be7y9beTBoyChz11qxZ4z8xqPY1rJnVRmYuAe/zzHUXbF4wFrpI0EOhsZl+b2WhgC0nfJAWX3G9mX5OeNz5P0i+BTc3s8xL78pD/WwtMMLNPPabzC6WM7kKc6XTgaeriTPOOQZ4RZjbHzL4AXqIuvOVoSVNIz2T3IOV9F9wDi794dPZ9hHRcC54lxZ7uQYopXUPSakBXM3u1TL8B3jaz8f55F297rKSpwE8oETBjZkPMrMbMaujUqcTuhhBCqFZz3PVdLzYzR3b9l/7vosznwu+l+levfjO7XNKjwP6kF3X0M7NXSAPYMaTM7RO97F2SJpCSy56UdJKZPVNcZwV9y8aZLpD0FimKs5JjkK0fUiDKipK+RTo7sJNngw9lyYjUz/zfcm1MJJ0pmAU8BawLnAxM9vWl+p2tv9DGU2b2wwr2JYQQQjNojhn1CNKMcB0ASWsDz1P3copjSFGd1ViBdNoZ0ruf620vaXOfjQ8mnaLt7quGAmcAmNlML5sXk9kYpeJM845BpdYkDZZzJHUBvp9XyMw+8TKFswvHZNZ9BfwTOBoYT5phn+3/lut3sfHA7pK28P1YTdJWJcqGEEJoBk0+ozazmZJ+A4yWtJB0+nYgcLOkc4AP8OvGVfgM6CFpMuk1jv2hXuzmGT7oLCSdRn7c170n6WWWfPtVvZhMr+8x4KQyb9sqdifwsIriTEscg+MlHQzUmNmgUhWa2TRJL5JO/c8indIv5QTScZ1Pen1l1rPAd8xsvqRngY2oG6hz+53Tlw8kHQ/cLekbvvgC4LUyfYoI0RBCaELLRISopHlm1qi7jf3abC2wo5nFXU4tICJEQwiheioRIbpcJ5NJ6gfcDFwVg3TLiWSyEMLypjVTypaJQIvGzqbN7Gkz28TM/tDUfVrWKD2zfmTO8g0k3dcafQohhNCw5XpGvTzy553lj7AtNb8eX28ADyGE0DYsEzPq1lCcLKaWSVdbT9JTXuZGSW9LWrdEYli59LLBSslrLxTu2HZ7Snre+3mkl1+cES6pg6QrldLKpks6zZdfLuklX3ZlcxzvEEII+WKgzlEiWawl0tUuBJ7xMg8Cm2TWLU4MM7O3KZ9eNtfMenufs6f91yeFoBwIXJ7T/inAt4AdCvvpj5YdBvTwZZfmHrQQQgjNIgbqfK2VrrYH8Fdv8wlgdmZdNjEMyqeX3Z35NxsvOszMFpnZS9QlkWX1A27w9LbCfs8lRY7eJOlwYH7OdhEhGkIIzSQG6nytkq7m7ZayODEsk172HZ/lPsqS6WVW4nO2b3lt1dtvH7R7A/cDhwJP5HUuIkRDCKF5xECdr1XS1XzZ0d7mvqRT6nkaSi/rn/l3XBV9HA4MkLSi92FtpbdldTKzx0gJbz3LVRBCCKFpxV3fOVoxXe1iUgpYf9J17HeBT4ElHk+rIL3sG0pZ5iuQXkZSqZuArYDpntr2F9JM+u+SChnmZ1ZRXwghhKW0TCSTLQ8qSVfzmM6FZva1pF2B6/1VnNW08xYppvTDxvd26UQyWQghVK9dJpMtgzYB/iZpBeAr0huvQgghtGMxULeQStLVzOx1YIelbKfr0mzfFCJCNISwPGqtGNG4mawFSTpY0rlLWcd6kiZIelFSn6bqW1Ebx0u6rjnqDiGEUJ2YUbcgM3uI9P7rpfEd4BUz+0mlG0jqYGYLl7LdEEIIrSBm1E3EozhfkXSTpBmS7pTUT9JYSa9L6p2dqUo6ystNkzTGl+VGeGba6AlcAewvaaqkVSX90MvPkDQ4U3aepEv87u9d82JAJR2UmZ0/7Y96Fe/XepLulzTRf3ZvxsMYQgihSMyom9YWwFGkKM6JpOel9wAOBs4DhmXKDgK+Z2b/ltTZl2UjPL/257cXM7OpkgaR7uo+VdIGwGCgFynFbLikQ81sGCmydIaZDfJ6/h/Q3cws095zwC6+7CTgF8D/LdqnPwJXm9lzSvnmTwLfLt5xSad4/6FLXuhZCCGExoiBumm9aWa1AJJmAiN8EKylLkq0YCwwVNLfgAd8WV6EZzk7AaPM7ANv805gT9IXgoWkZ6BhyRjQR4FHfPlGwD2S1gdWBt7MaaMfsLW0OMhsTUkdzezTbCEzGwIMAVC3bvHMXwghNJE49d20iuNDs9GiS3wpMrMBwAXAxsBUT0GrJLo0q1zk6BeF69JlYkCvBa4zs22B/2LJGNKCFYBdzayn/2xYPEiHEEJoPjFQtxJJm5vZBDMbBHxIGrDrRXg2UM0E0puz1pXUgZRCNjqnrVIxoJ2Af/vnUjenDQdOzdQVEaIhhNCCYqBuPb8r3AQGjAGmkSI8/0GK8JxGusaN3xR2cHEFZvYu8D/ASN9+ipn9PaetjsAjkqaTBvJCDOhFwL2SniV9WcgzEKjxm9BeAgY0am9DCCE0SkSIhiYXEaIhhFC9UhGiMaMOIYQQ2rC46zs0uYgQDSEsz1o6SrTdzKg9iGRr/zyvtfsD6U1XktZtwvqGSjqy4ZIhhBCWFe1mRm1mJ7V2H5qSpBULz1svy22EEEIor6IZtaTj/K7faZJul7SppBG+bIQnVhVmdNdLGilplqS9JN0s6WVJQzP1zZP0e0lTfPv1ctrcy2Myp3rEZUdv+5BMmTv9RRc9JL3gZadL2jKnvlGSajK/12vfy1wtaYz3eSdJDyhFgF5a4ti8JWmwt/+CpC18eRdJD/oxmyZptxKH9zTvR62k7r5tb0nP+34/L6mbLz9e0r2SHialkEnSdUrRoI8C38xs/4B/PkTS55JWlrSKpFm+/GSlSNBpShGhq2X+hldJGgkMlrS6/w0nen8OydmHEEIIzaTBgVpSD+B8YB8z2x44HbgOuM3MtgPuBK7JbLIWsA/pEaCHgauBHsC2mWdwVyc9SrQj6XGhC3OaPhv4uZn1BPoAn5MeXzrB+9UJ2A14jPTI0B+9bA3wrwZ2q1z7X5nZnsANwN+BnwPbAMd7KEmeuWbW24/LH3zZNcBoP2Y7AjNLbPuh9+N632eAV4A9zWwHUtToZZnyuwI/MbN9gMOAbsC2pHdXF74MTKHudZl9gBmkFLOdSc9eAzxgZjt5/14GfpppYyugn5n9X9Lf/hkz2wnYm/RY2erFOyHpFEmTJE1izpwSuxpCCKFalcyo9wHuM7MPYXGs5a7AXb7+dlKedcHDlp75qgXeM7NaM1tEGqi6eplFwD3++Y6i7QvGAldJGgh0NrOvzWw0sIWkb5LCPe73U7PjgPMk/RLY1Mw+by33XzYAACAASURBVGCfyrVfeLtVLTDTzN41sy+BWaRQkjx3Z/7d1T/vQxp8MbOFZlZq9CrEh06m7vh0Ij3fPIO6LzoFT2WiRfcE7vb63wGe8fa+Bv5X0rdJiWRXedk+wLO+7TaSnlWKNz2mqI17M2/b2hc4V9JUYBQpvWyT4p0wsyFmVmNmNXTqVGJXQwghVKuSgbqSWMvs+mxsZnGkZqlr4vXqN7PLgZOAVYHxhdPCpC8Gx5Bm1rd42btIL774HHhS0j4N9Lc5+1/tg+mFNhZm6v81MNLMtgEOYsloz8/KtJ31LPB9YAHwNOnLyB6kcBWAocCpHh96cZk2BByRiRDdxMxernDfQgghLKVKBuoRwNGF075KsZbPAz/w9ceQ3sJUbbuFu5N/lLe9UsRmrZkNBiYBhYF6KCkGEzOb6WU3A2aZ2TWkGfF2S9t+lfpn/h3nn0cAP/P+dZC0ZhX1ZaM9jy9TbgzwA69/fdKp6ey6M4Bx/tKOdUjHsHAKviPwrqSVSH/DUp4kXUeX78sOZcqGEEJoYg3e9W1mMyX9BhgtaSHwIilW8mZJ5wAf4NeNq/AZ0EPSZGAOPtBJGuBt3gCcIWlv0kzzJeBxX/eepJdZ8pWR/YEfS1oA/Ae4xOt7DDjJTws32H6lcur9htJ7n1cgnZKHdC1/iKSf+j78DBhXpk9ZVwC3SjoLP51dwoOkU+y1wGssmfM9AehC3Qx6OvC+1UXR/crLvO3bdyzRxq9J192n+2D9FnBgmT7Rq2NHJrXwc4YhhLC8apUIUUnzzGyNRm67Gmlg2bHMdd8WI+kt0vuhS2VltzsRIRpCCNVTiQjRZeo5akn9gJuBq9rCIB3yRTJZCGF515LpZK0yUDd2Nm1mT5Nzx3FrMrOurd2HEEIIy692EyHaXCTVSLqm4ZJLbHORpLMbLtn8PDDm3NbuRwghhHzL1KnvtsjMJpHuSl8mmdlD1D07HkIIoY2peEat1okRXVvSMG9jvKTtfHm9eNGcbecpRXtOlvS0x2qO8j4d7GUqiR6tldRZyUeSjvPlt0vqJ6mvpEd82UW+r4V2BmbqOV/Sq5KeJqWJFZb39H2brhQ5upakb/od6UjaXpJlju8bklaTdJSkGf73GEMRSV0lvaL0MpIZSnGr/SSNVYpE7e3ljpd0nX+uV6fSo19X+nGYLum0hv9rCSGE0FQqzfpurRjRi4EXvY3zgNt8eV68aLHVgVFm1gv4FLgU+C4pdvMSL1NJ9OhYYHfv/yxvD2AXYHxO+e7A90iJYBdKWklSL9Jz5zsAh5PiPAtuA37p+1gLXGhm7wOrKD173Yc0Y+8jaVPSI1bzSdGi3/O/x8E5/QDYAvgj6bny7qRnxvcgHb/zcsrn1XkK8C1gh8zfuh5FhGgIITSLSmfUrRUjuofXjZk9A6yjlPFdL140Z9uvgCf8cy0pd3uBfy70oZLo0WdJ8Zt7kiJBt5W0IfCxmeW9LvNRM/vSj9X7pGeZ+wAPmtl8M5uLn2r2fens0agAt3o7kEJldvffL6N+BOhYYKikk4EOOf0AeLPo2I/I/F265pTPq7MfcEPhGGfiS5cQEaIhhNA8Kh2oWyVG1NutV65MvGjWgky4x+J++KC1on+uFz0q6eeZ0+obkAJD+vjPKFLAy5HUDZjFsvubjQWt9oH1Z73NTUkvB9meTASomQ0ALiDlj09V/gtDio999u9S7+9Qos5K/vYhhBCaSaUDdavEiJIGpWO8zb6kN03NVel40aooJ3rUzP6UybV+x8z+CawLbGlms7yfZ1N6oM4zBjhM0qp+Pf0gAH8WfLakwun0Y6lLFxsD/Bh43b9cfAzsT5r1FiJWJ5jZIOBDSr8wpGIl6hwODJC0opdZe2nbCSGEULmK7vpuxRjRi4BbJE0H5gM/8W1z40UlTfXrzZXKjR7NMYG6U8HPAr+lii8mZjZF0j3AVFJkZ3aQ/wlwg1Li2iz8OJrZW0rx2oUbxZ4DNjKz2f777/zmN5G+SE3zMwA3mdn+lfatSL06Sa/I3IoUIboA+Avp/oSSIkI0hBCaTqtEiMLSxYiGti0iREMIoXpaHiJEw7IhIkRDCMu7lowQbbVksuVpNq3GpZPl3TFeyXaHStq6MduWqG8DSfc1VX0hhBCaVkSINgEzm2RmAxsu2SQOBXIH6sINX9XwG+aObLhkCCGE1hADdRmSVpf0qCd1zZDUX9JOkp73ZS9I6phNJ8up4xxJEz3V6+Jqyqh+GtxupMfJfuePj22ulIJ2maTRwOkqnxh3jfd9lqQjfXlXSTP8c24KmaTLJb3ky65s0oMcQgihrLhGXd5+wDtmdgAsDih5EehvZhM9OSwvJAUvvy+wJSmlTMBDkvY0szENlQE+IqXB7W5mH0pa28w+lvQQ8IiZ3efbQwpN2ct/f5iUGHerpBNJiXGHenPrk57F7k56HK34lHc2hexrpQjXtUlpbt3NzCR1LrGvp/j20KVLmUMaQgihGjGjLq8W6KeUGd6H9IrNd81sIoCZzS2Rilawr/+8CEwhDZDFeeKlyuSlwZVyT+ZzucS4YWa2yMxeIiWmFctLIZsLfAHcJOlw0mNy9UQyWQghNI+YUZdhZq8p5XTvT3p2ejjVpXQJ+K2Z3VhtGY9HrbStz8qsy0uMK7Sb15cl2vSZdW/gO6SAm1NJXyJCCCG0gJhRl+EBIvPN7A7gStKLODaQtJOv79jADVxPAidKWsPLbyjpmxWWyUuDg/SCkXpvC8tYmsS4eilk3q9OZvYYcAZQTaBMCCGEpRQz6vK2Jd24tQhYAPyMNOu8VtKqpOvT/bIbSKoBBpjZSWY2XNK3gXF+LXkeKRb0/UL5UmVKpMEdD/wV+IvPuPPu1l6axLibqJ9Cdj/wd0mr+L6fWUV9IYQQllKrJZOF5Vckk4UQQvVKJZPFqe8QQgihDYtT36HJRYRoCKE9aKkY0ZhRtxGNjCG9SNLZzdWnEEIIrS9m1G2EmU0ivVs7hBBCWKxdzqhzojnLxW5eL2mkx27uJelmSS9LGpqpb56k30ua4tuvl9NmraTOSj6SdJwvv11SP2ViSH2mfLPHg87yO7wL9Zwv6VVJTwPdMst7Shrv+/CgpLUkfVPpfd9I2l6SZfbtDUmrSTpKKR51mqQxFFGKTJ0uaRWlSNWZkrZpqr9FCCGE8trdQC2pBymacx8z2x44HbiOFLu5HXAnKXazYC1SwMeZwMPA1UAPYFtJhWeKVwemmNmOwGjgwpymxwK7+7azgD6+fBdgfE757sD3SNGiF0paycNXfgDsABwO7JQpfxvwS9+HWuBCM3sfWMWjTvuQZux9JG0KvG9m84FBwPf8WBxc3AlPYXsIuBS4ArjDzGYUl5N0iqRJkiYxZ07O7oQQQmiMdjdQkx/NWS5282FLz7DVAu+ZWa2ZLQJmAl29zCLqYjzvKNq+4FlgT/+5njTQbwh8bGZ5r7x81My+9H6+T4r87AM8aGbzzWwuaQAtZJB3NrPRvu2t3g6kAJTd/ffL/N8+3h9IXyCGSjoZ6JB/yLgE+C5QQxqs64kI0RBCaB7tcaCuF5OZIy92cxFLRnAuovQ1/rz6x5AGyD7AKFIYyZHUDZjFsm0tzLRV7YPvz3qbmwJ/B7YnfZEYA2BmA4ALgI2BqYUktCJrA2uQEtFWqbL9EEIIS6E9DtR50ZxLE7sJ6TgWUsJ+lLe9mf0TWBfY0sxmeZmzKT1Q5xkDHCZpVUkdgYO87jnAbH9xCMCxpFPwhW1+DLzuZwI+JmWXjwWQtLmZTTCzQcCHpAG72BDgV6TLAoOr6G8IIYSl1O7u+i4Rzbk0sZuQXorRw2/cmgP0B5A0wNu8wctNoO708rOkF31U/KXAzKZIugeYCrzNkoP8T4AbJK1GugZ+gm/zlkeTFm4Uew7YyMxm+++/k7Ql6UzDCGCaZ5zfZGb7+01vX5vZXZI6AM9L2sfMninVz14dOzKphZ4vDCGE5V1EiDYBSfPMbI3W7kdbERGiIYRQvYgQDSGEEJZB7e7Ud3OI2fSSIkI0hNAeRIRoWEJjIkZDCCEs+2JGvYyIiNEQQmifYkbdyjyW81GP8Jwhqb/Hdj7vy16Q1DEbMVq0/fqSxkia6tv38eW5saaSTpY00eu+3+8SR1IXjx6d5j+7+fIfex+mSrrR7/wOIYTQQmKgbn37Ae+Y2fZmtg3wBCnl7HSP9ewHfF5m+x8BT5pZT1KYyVRfXirW9AEz28nrfhn4qS+/Bhjty3cEZkr6NulRs929/oWk58zriQjREEJoHnHqu/XVAldKGgw8AnwCvOsZ23hUKP4sdJ6JpGfAVwKGmVlhoC6ONX3AP28j6VKgMylt7Elfvg9wnLe5EJgj6VigFzDR21+VFGdaj5kNIQWjoG7d4pm/EEJoIjGjbmVm9hppMKwlBaAcRhUxoWY2hpTf/W/g9sJbufKK+r9DgVPNbFvgYspHggq41cx6+k83M7uo0r6FEEJYejFQtzJPAZtvZncAV5LeprWBpJ18fUdJJc98ZN6E9Rfg/5FOW0PpWNOOwLs+A8+exh4B/Mzr7OBv3BoBHCnpm758bW8vhBBCC4lT361vW1KM5yJgAWmwFHCtpFVJ16f7ZTeQVAMMMLOTgL7AOZIWAPPw09eUiDUlZXZPIEWQ1pIGbkiv+xwi6aeka9E/M7Nxki4Ahktawfv3c9+2pIgQDSGEphMRosup1ow1jQjREEKoXqkI0ZhRhyYXyWQhhPaiJdLJ4hr1cqqS2bSkQyVt3RL9CSGE0DgxULchSlryb3IoEAN1CCG0YTFQtzJJXSW9LOnPwBTgWEnjPFHsXklreLl6aWU5dQ2TNFnSTEmnZJbPy3w+UtJQTx47mHQj21RJm0vqKWm8pOmeUraWbzNQ0ku+/K/NfUxCCCHUiYG6begG3AZ8l5QU1s8TxSYBZ0lamcrSyk40s15ADTBQ0jqlGjSz54GHgHP8Gek3vA+/NLPtSHeEF9LMzgV28OUDln53QwghVCpuJmsb3jaz8ZIOJJ2KHutJYCsD40gDeb20shwDJR3mnzcGtgQ+qqQDkjoBnc1stC+6FbjXP08H7pQ0DBhWYvtTgDSL79KlkiZDCCFUIGbUbcNn/q+ApzJJYFub2U99ednn6CT1Jc20d/VZ94vUpY5lty2XRFbKAcCfSAlqk/MCWMxsiJnVmFkNnTo1ookQQgh5YqBuW8YDu0vaAkDSapK2Al6h4bSyTsBsM5svqTsp4azgPUnf9hvVDsss/xQPPDGzOcDswtu3gGOB0b7NxmY2EvgFdRnhIYQQWkAM1G2ImX0AHA/cLWk6aeDubmZfkZLFrpU0DXgKWEXSBpIe882fAFb07X7t2xacS3rhxzPAu5nlfyWlmr0oaXPgJ6Sby6YDPYFLgA7AHZJqSbP0q83sk2bY/RBCCDkimSw0uUgmCyGE6pVKJosZdQghhNCGxV3foclFhGgIob2ICNFQMUk1kq5pgXbekrRuc7cTQgghiRn1csLMJpECUkIIISxHYkbdxklaXdKjHh06Q1L/vDhRSX0lPZKzfV9JoyX9TdJrki6XdIxvV+t3eyNpPUn3S5roP7v78nUkDfc7w28kPdMdQgihhcSMuu3bD3jHzA6AxQliLwL9zWyipDXJjxPN2h74NvAxMAu4ycx6SzodOA04A/gj6dGr5yRtAjzp21wIPGdml0g6gEL6WJFIJgshhOYRA3XbVwtcKWkw6VnoT8iJE/XI0VImmtm7Xu4NYHim7r39cz9g60w9a/qLP/YEDve2HpU0O68BMxsCDAFQt27xzF8IITSRGKjbODN7TVIvYH/gt6RBttqB8MvM50WZ3xdR99/ACqT40SVm5z5wx8AbQgitJK5Rt3GSNgDmm9kdwJWkaNCG4kQbYzhwaqbdnv5xDHCML/s+sFYTtBVCCKFCMaNu+7YlxXouAhYAPyPd0HWtpFVJ16f7ZTeQVAMMMLOTqmhnIPAnjw9dkTRADwAuJkWaTgFGA/9Yyv0JIYRQhYgQDU0uIkRDCKF6ESEaQgghLIPi1HdochEhGkJoLyJCNJTUUpGhmfb6StqtpdoLIYSQxIx6GbU0kaGSVjSzr6vcrC8wD3i+MW2GEEJonJhRtzFLGxnqdfzC40GnSbrcl42SdJmk0cD5kt6UtJKvW9NftrGSl/uDtzdDUm9JXUl3gJ8paaqkPi10OEIIod2LGXXbs1SRof6s86HAzmY2X9LamdWdzWwvL9cVOAAYBvwAuN/MFnjAyepmtpukPYGbzWwbSTcA88zsyhLtRoRoCCE0g5hRtz21QD9Jg33muglFkaENnLbuB9xiZvO9/MeZdfdkPt8EnOCfTwBuyay727cdQ4oS7dxQp81siJnVmFkNnTo1VDyEEEKFYqBuY8zsNaAXacD+LXAY1UV4qkz5zzLtjAW6StoL6GBmM7LdKO5WFe2HEEJoQjFQtzFNEBk6HDhR0mpefu0yZW8jzZ5vKVre37fdA5hjZnOAT4GOjdilEEIISyGuUbc9SxUZamZPeE73JElfAY8B55Vo607gUvxUd8ZsSc8DawIn+rKHgfskHQKcZmbPltqBXh07MqkFni0MIYT2ICJE2zFJRwKHmNmxmWWjgLP98a9GiQjREEKoXqkI0ZhRt1OSrgW+T3p9ZpOKZLIQQnvS3OlkMVC3U2Z2WonlfVu4KyGEEMqIm8laQbk4TknHS7quGdse6qe8Ky3fVdIM/1wyZCWEEELzWO4HaiVtZj/9ju2+QORmhxBCaFCbGcCaks8CX5b0Z2AKcKykcZKmSLpX0hperl40Z1E99eI8fflbHkjygv9s4cs3lTRC0nT/dxNfPlTSVZJGkkJHGorj3FjSE5JelXRhpj/DJE2WNNOTwJDUweuf4bGhZ/ryzb2OyZKeldQ9U38/X/aapAMzx+xZP0ZTSs34QwghtKzl+Rp1N1Li1iDgAaCfmX0m6ZfAWZ6BfQ/loznz4jwL5ppZb0nHAX8ADgSuA24zs1slnQhcQ4rzBNjK+7BQ0kWUieMEegPbAPOBiZIe9buwTzSzj/0xrYmS7ge6Ahua2Tbex0KK2BDSI1uvS9oZ+DOwj6/rCuwFbA6M9C8a7wPfNbMvJG1JemSr3t2HpUSEaAghNI/lckbt3jaz8aTAkK2BsZKmAj8BNiUN5A1Fcy4R5+nBHwV3Z/7d1T/vCtzln28H9siUv9fMFlbY96fM7CMz+5z0JaNQz0BJ04DxwMbAlsAsYDNJ10raD5jrZwx2A+71fb4RWD9T/9/MbJGZve7bdwdWAv4iqRa4149ZxSJCNIQQmsfyPKMuxGWKNPD9MLtS0nY0EI1pZq9J6kV6hOm3koab2SWF1dmiparI6U8l6kV4SupLCjrZ1V+2MQpYxcxmS9oe+B7wc+Bo4AzgEzPrWWn9wJnAe8D2pC9wX1TR3xBCCM1keZ5RF4wHds9cR15N0lbAKzQQzZkT57ljZnX/zL/j/PPzpDdRARwDPFeiTw3FcX5X0tp+ivtQYCzQCZjtg3R30pkCJK0LrGBm9wO/AnY0s7nAm5KO8jLywbzgKEkrSNoc2Ax41et/18wWAccCHcr0L4QQQgtZnmfUAJjZB5KOB+6W9A1ffIHPlvtTFM3p16pvMrP9yY/zLPiGpAmkLzuF2fpA4GZJ5wAfUPd2qmJLxHECawE1ZjbI1z9HOnW+BXCXmU3yU9IDJE0nDazjveyGwC2ZO9v/x/89Brhe0gWk09p/Bab5uleB0UAX0nXsL/zGu/t9cB9JdWcAlhARoiGE0HQiQrQRJL1FGlg/bO2+tEURIRpCCNVTRIiGlhIRoiGE9qY5Y0RjoG4EM+valPX5jWJfmdnzTVlvhW1fRPlHxUIIIbSi9nAzWUX8hqvWOh59qTKprPjGtxBCCMundj1Qq+kSzLpKekXSTZ4QdqekfpLGSnpdUm8vt7ani02XNF7SdpK6UpRUpsoSzgZLWkPSLUqJZNMlHSHpp5KuzvTtZElX+efjvNw0SbfnHI/cNDNJR/l+TZM0phn+FCGEEEqIWVnTJJhBukP7KFI610TgR6SgkoOB80iPWV0MvGhmh0rah5Ri1lPSDWROP0t6mMoSzgYDc8xsW99uLeArYLqkX5jZAt+3/5LUAzgf2N3MPpS0ds4+lEozGwR8z8z+rbrksyUokslCCKFZxEDtCWZKmdeFBDOAlUnPR9dLMCtRz5tmVgsgaSYwwszMH6vq6mX2AI7wep6RtI6WjCUt2BU43D/fDlyRWZdNOOtH3XPbmNlsb/8Z4EBJLwMrmVmtpNOA+wp3qpvZx9kGtWSaWWFx4XG2scBQSX8jfZmpx8yGkAZ61K1bPEoQQghNJAbqJkgwc19mPi/K/L6IuuMs6quk7lIJZyqx/U2kWfwrwC0NlC1YgRJpZmY2wGfYBwBTJfU0s48q6HcIIYSl1K6vURdpdIJZFcaQgkgKd3p/6DP04qSyShPOhgOnFn7xU9+Y2QRSFviPqMskHwEcLWkdL7vEqe9yaWaSNjezCR7I8qHXHUIIoQXEQO3M7APgeFKC2XTSwN3dzL4ixYReq/RCjKeAVSRtIOmxKpu5CKjx+i8nvSAEUlLZYap77eVA4AQvdyxweon6LgXWKtzoBeydWfc3YGzhdLiZzQR+A4z2slfl1HcM8FNfPxM4xJf/zm9Ym0H6sjEtZ9sQQgjNIJLJllOSHgGuNrMRLd12JJOFEEL1VCKZLGbUyxlJnSW9BnzeGoN0CCGEphU3ky1nzOwT0iNcrSYiREMI7U1zRojGjLqIpFGSavzzY6WeG86Uv0RSv5boTwPlNpB0X5n1nSX9d6XlQwghtA3tbqD2u5kr2m8z299nqOXKDDKzp5umd40jaUUze8fMjixTrDOweKCuoHwIIYQ2oM0O1JJWl/Sox1bOkNRf0nckveh3IN8sf7+0Kov4zEaFbixpX+XEhRZt95akdf3zr5RiQp+SdLeks335UElH+udS/XtL0sXeVq08mjOnvV/4+mlKiWgFR/l+veZ3hSPpeO/3w8Bw38cZvq6Hl5+qFBm6Jeku88192e+KyndVigyd4j+7+fK+PqO/z/f9Tkl5z4KHEEJoJm12oAb2A94xs+3NbBvgCWAoKcpzW9L19Z9JWpkU8Xm6mW1PSuvKi/jsRorl3IEUGnIBKYpzR2AScFapjvip5yOAHUiJYfVORUtaJa9/mSIfelvXA2fnbP99Ukzozr4f2TSyFc2sN3AGcGFm+a7AT8xsn6LqBgB/9PCSGuBfwLnAG2bW08zOKSr/PvBd719/UmRpwQ7e7tbAZsDuxX33/p8iaZKkScyZk1ckhBBCI7TlgboW6CdpsM8iu5JiOl/z9bcCe5IT8WlmX+fU97aZjffPu1AXFzqV9DzzpmX6sgfwdzP73Mw+JT33XKxbif4VFKI3J1MXKZrVD7jFzOb7fmQjPktt+1RxFKgbB5ynlFe+qZnlfXHJWgn4i1Lc6b2kY1Pwgpn9y8wWAVNL9B0zG2JmNWZWQ6e8VNQQQgiN0Wbv+jaz1yT1AvYHfktK4crTUDRmQXH0Zr240DIqOd3bUJlCpOhC8o97uf0ote1nOWUxs7skTSBFfj4p6SRgVpm+nQm8B2xP+vL2RU7b5foeQgihmbTZGbWkDYD5ZnYHcCXphRFd5RGfpMSu0TQu4rNUXGgpzwEHSVrFr2UfkFPmlRL9q9Rw4ERJq3mf8t5uVRFJmwGzzOwa4CFgO+rHlGZ1Ip2VWOT97tDYtkMIITSttjw72pYUXbkIWEC63tuJ9HanFUmvkrzBzL6SVIj4XJV0fbqf0usobzKz/YsrNrMPJB1PigstvCHqAuC14rJefqKkh0jRmW+TrmnPKSrzhaQTivtXbgf92vcAMzvJzJ6Q1BOYJOkr4DHSizUaoz/wY0kLgP8Al5jZx0rvx54BPA78KVP+z8D9SjnfIykxU69Ur44dmdSMzxSGEEJ7EhGiFZK0hpnN8xnvGOAUM5vS2v1qiyJCNIQQqqcSEaJteUbd1gyRtDWwCnBrDNIhhBBaQgzUFTKzH7V2H5YVESEaQmiPmitGtM3eTNYeecDIbiXWHS/puiZo46JCWEsIIYS2r90O1ErazP77DWh9SXe3hxBCCEA7G6hzokSPzYsRVcORpPXiTX35Wx7Q8oL/FB7/2lTSCI/zHCFpE18+VNJVkkaS0tUGAGd6zGefnF3YQNITkl6XdEWmPz9Uih6dIWlwZvl+vm/TJNV75aWkkyU9LmlVSZt73ZM9TrS7P+r2pqSVvPyavo8rLd1fIoQQQqXa4zXqbsAJwCBS4lc/M/vMU7zOUsrYvocUBTrRH/MqTvYqxJseACApG8U118x6SzoO+ANwIHAdKb70VkknkiI6D/XyW3kfFkq6CJhnZleW6HtPUqTnl8Crkq4lhZAMBnoBs0m534cCY4G/AHua2ZvFz2VLOhXYFzjUzL6UNIT0qNjrknYG/mxm+0gaRXpufBjwA+B+M1tQ3DFJpwCnANClS4nuhxBCqFZ7HKjfNrPxkg6kLkYUYGVS9Ga9SNKcOmqBK332+oiZPZtZd3fm36v9866kjHCA21kyx/teM1tYYd9HmNkcAEkvkWJP1wFGmdkHvvxOUnTpQmCMmb3p+5GNGj2WlP99qJkt8DMJu5GeAS+UKTxffhPwC9JAfQJwcl7HzGwIMARA3brFM38hhNBE2uNAXQjzyI0RlbQdDUSSFsebShpuZpcUVmeLlqoipz+VyIvzLBVdWi6SdAZpdr4R8CbpEsgn/hKPJTtqNtYvGewFdDCzGVX0N4QQwlJqV9eoi5SKEW0wklT14013zKzun/l3nH9+nnTaGOAYUiRpnnIxn6VM4P+3d28xdk1xHMe/P63WXW9IqahG4/KglwgV4l5BhJc+aAQPTXgQl0SICZFIvHhxS6QhbpEIoi6tEjTFg0RKqy1DDdOQdNIyRIl4EOXvYf1nnIwz0xk9M2fv4/dJds7ZApYTEAAABUBJREFU6+w265fZM2v22nvWH86VNEvSJGA5ZenSD7P9+Oxz49T3ZuAGYI2ko3PW4JtcmWzgQbsFDcc/S5kheHqMfTMzs330f7yiBoZfRjSvlve2JGmz5U0HTFUpiLEfZdAEuBl4StLtwA+UKeRmXgdWSboSuAmYDpwWEfeMkGOXpC7K0p8C3oyI1TB43/iVfLq9H1ja8O8+yD/TekPSUsovECsl3U2ppvUCZclUgOeA+/hnWn9EXkLUzKx1vIRoC0n6ljKw/tjuvrSSpGXAlRFxzWiO9xKiZmZjJy8hav9FPll+KeV+vJmZTTBfUVvLSfoV6Gl3P1psFtBRMyU4U510Yi5n+rfjIuKIoY2+orbx0NNs+qbOJG10purrxEzQmbmcafT+z099m5mZVZ4HajMzswrzQG3j4fF2d2AcOFM9dGIm6MxczjRKfpjMzMyswnxFbWZmVmEeqM3MzCrMA7W1TNa/7pHUK+nOdvdnLCQ9JalfUndD2wxJ67L+9zpJ07Ndkh7JnJ9KWjz8/9w+ko6V9J5KDfbPJd2S7bXNJekAlVrvWzPTvdl+vKQNmelFSVOyfWru9+bnc9vZ/5FImiRps6S1uV/rTCq16z+TtEXSxmyr7bkHIGmapFWSvszvqzMnIpMHamsJlYIgj1JWMTsFWC7plPb2akyeodQZb3QnpbTofGB97kPJOD+364GVE9THsdoD3BYRJwNLgBvza1LnXL8DF0TEAkoFuEskLaHUZH8wM+0GVuTxK4DdEXECpezs/W3o82jdAmxr2O+ETOdHxMKGvy2u87kH8DDwVkScBCygfL3GP1NEePO2zxul5vbbDftdQFe7+zXGDHOB7ob9HmB2vp9NWcgF4DFgebPjqrwBqymFWToiF3AQ8AlwBmU1qMnZPnguAm8DZ+b7yXmc2t33Jlnm5A/5C4C1lAI7dc/0LTBrSFttzz3gMEpZYA1pH/dMvqK2VjkG2NGw35dtdXZUROyCUqUMODLba5c1p0cXUcqi1jpXThFvoVSEWwdsp9RT35OHNPZ7MFN+/gswc2J7PCoPAXcAf+X+TOqfKYB3JG3KSn5Q73NvHqX64dN5i+IJSQczAZk8UFurqElbp/7tX62ySjoEeBm4NUrt8WEPbdJWuVwR8WdELKRchZ4OnNzssHytfCZJlwP9EbGpsbnJobXJlM6KiMWUKeAbJZ0zwrF1yDQZWAysjIhFwG/8M83dTMsyeaC2VukDjm3YnwPsbFNfWuV7SbMB8rU/22uTVdL+lEH6uYh4JZtrnwsgIn4G3qfcf58maaB2QWO/BzPl54cDP01sT/fqLOAKlTK5L1Cmvx+i3pmIiJ352g+8Svmlqs7nXh/QFxEbcn8VZeAe90weqK1VPgbm55OqU4CrgDVt7tO+WgNcl++vo9zjHWi/Np/qXAL8MjD1VSWSBDwJbIuIBxo+qm0uSUdImpbvDwQuojzQ8x6wLA8bmmkg6zLg3cgbhlUREV0RMSci5lK+b96NiKupcSZJB0s6dOA9cDHQTY3PvYj4Dtgh6cRsuhD4gonI1O4b9N46Z6PUrP6Kcs/wrnb3Z4x9fx7YBfxB+U14BeW+33rg63ydkceK8oT7duAz4LR293+YTGdTpto+BbbkdlmdcwGnApszUzdwT7bPAz4CeoGXgKnZfkDu9+bn89qdYS/5zgPW1j1T9n1rbp8P/Dyo87mX/VwIbMzz7zVg+kRk8hKiZmZmFeapbzMzswrzQG1mZlZhHqjNzMwqzAO1mZlZhXmgNjMzqzAP1GZmZhXmgdrMzKzC/gbw+YBb6/jqwgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Visualizing Target name frequency: they seem well distributed\n",
    "df_values = df['target_names'].value_counts()\n",
    "df_values.plot(kind='barh',color='c', width= 0.8)\n",
    "plt.title(\"Target Name Frequency\")\n",
    "plt.rc('xtick', labelsize=8) \n",
    "plt.rc('ytick', labelsize=8) \n",
    "#How do I annotate each bar?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>preprocessed</th>\n",
       "      <th>target</th>\n",
       "      <th>target_names</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11298</th>\n",
       "      <td>nhl team milwauke read report possibl nhl move...</td>\n",
       "      <td>10</td>\n",
       "      <td>rec.sport.hockey</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11299</th>\n",
       "      <td>turkei cypru bosnia serbia greec armenia azeri...</td>\n",
       "      <td>17</td>\n",
       "      <td>talk.politics.mideast</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11300</th>\n",
       "      <td>arrog christian previou articl phsd vaxc monas...</td>\n",
       "      <td>15</td>\n",
       "      <td>soc.religion.christian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11305</th>\n",
       "      <td>hezbollah apr yuma acn colost edu repli long l...</td>\n",
       "      <td>17</td>\n",
       "      <td>talk.politics.mideast</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11313</th>\n",
       "      <td>stolen cbrrr stolen pasadena blue white honda ...</td>\n",
       "      <td>8</td>\n",
       "      <td>rec.motorcycles</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            preprocessed  target  \\\n",
       "11298  nhl team milwauke read report possibl nhl move...      10   \n",
       "11299  turkei cypru bosnia serbia greec armenia azeri...      17   \n",
       "11300  arrog christian previou articl phsd vaxc monas...      15   \n",
       "11305  hezbollah apr yuma acn colost edu repli long l...      17   \n",
       "11313  stolen cbrrr stolen pasadena blue white honda ...       8   \n",
       "\n",
       "                 target_names  \n",
       "11298        rec.sport.hockey  \n",
       "11299   talk.politics.mideast  \n",
       "11300  soc.religion.christian  \n",
       "11305   talk.politics.mideast  \n",
       "11313         rec.motorcycles  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Filtering\n",
    "filtered_corpus = corpus_annot[(corpus_annot[\"target_names\"]== 'soc.religion.christian')  \n",
    "             |(corpus_annot[\"target_names\"]=='rec.sport.hockey')\n",
    "             |(corpus_annot[\"target_names\"]=='talk.politics.mideast')\n",
    "             |(corpus_annot[\"target_names\"]=='rec.motorcycles')]\n",
    "\n",
    "filtered_corpus.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part A) Test and Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Separating data in test and train\n",
    "docs_train, docs_test, y_train, y_test = train_test_split(filtered_corpus.preprocessed, # Independent variables\n",
    "                                                          filtered_corpus.target,       # Dependent variables\n",
    "                                                          test_size = 0.20,             # 20% becomes test data\n",
    "                                                          random_state = 12)            # Identifying the random seed for reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>apr</th>\n",
       "      <th>articl</th>\n",
       "      <th>ask</th>\n",
       "      <th>awai</th>\n",
       "      <th>believ</th>\n",
       "      <th>best</th>\n",
       "      <th>better</th>\n",
       "      <th>bike</th>\n",
       "      <th>call</th>\n",
       "      <th>case</th>\n",
       "      <th>...</th>\n",
       "      <th>try</th>\n",
       "      <th>univers</th>\n",
       "      <th>us</th>\n",
       "      <th>wai</th>\n",
       "      <th>want</th>\n",
       "      <th>word</th>\n",
       "      <th>work</th>\n",
       "      <th>world</th>\n",
       "      <th>write</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4389</th>\n",
       "      <td>0.095314</td>\n",
       "      <td>0.151092</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.588951</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.143302</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.328506</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.122648</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.066687</td>\n",
       "      <td>0.108134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10868</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.269275</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.301601</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3983</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.264009</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.175334</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.158794</td>\n",
       "      <td>0.080390</td>\n",
       "      <td>0.260711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10962</th>\n",
       "      <td>0.104566</td>\n",
       "      <td>0.082879</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.120131</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.159564</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.219479</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5434</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 91 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            apr    articl  ask  awai  believ  best    better  bike      call  \\\n",
       "4389   0.095314  0.151092  0.0   0.0     0.0   0.0  0.588951   0.0  0.143302   \n",
       "10868  0.000000  0.000000  0.0   0.0     0.0   0.0  0.000000   0.0  0.000000   \n",
       "3983   0.000000  0.000000  0.0   0.0     0.0   0.0  0.000000   0.0  0.000000   \n",
       "10962  0.104566  0.082879  0.0   0.0     0.0   0.0  0.000000   0.0  0.000000   \n",
       "5434   0.000000  0.000000  0.0   0.0     0.0   0.0  0.000000   0.0  0.000000   \n",
       "\n",
       "       case  ...  try  univers   us       wai  want      word      work  \\\n",
       "4389    0.0  ...  0.0      0.0  0.0  0.328506   0.0  0.000000  0.122648   \n",
       "10868   0.0  ...  0.0      0.0  0.0  0.269275   0.0  0.000000  0.301601   \n",
       "3983    0.0  ...  0.0      0.0  0.0  0.264009   0.0  0.175334  0.000000   \n",
       "10962   0.0  ...  0.0      0.0  0.0  0.120131   0.0  0.159564  0.000000   \n",
       "5434    0.0  ...  0.0      0.0  0.0  0.000000   0.0  0.000000  0.000000   \n",
       "\n",
       "          world     write      year  \n",
       "4389   0.000000  0.066687  0.108134  \n",
       "10868  0.000000  0.000000  0.000000  \n",
       "3983   0.158794  0.080390  0.260711  \n",
       "10962  0.000000  0.219479  0.000000  \n",
       "5434   0.000000  0.000000  0.000000  \n",
       "\n",
       "[5 rows x 91 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#TF-IDF Vectorizer\n",
    "vec_tfidf = TfidfVectorizer(max_df=0.7, min_df=0.1, smooth_idf=False)\n",
    "\n",
    "#Fitting TF-IDF Vectorizer to !train data!\n",
    "fitted_vec = vec_tfidf.fit(docs_train)\n",
    "\n",
    "#Transforming the data according to the trained vectorizer\n",
    "transformer = fitted_vec.transform(docs_train)\n",
    "\n",
    "#Feature names\n",
    "features = vec_tfidf.get_feature_names()\n",
    "\n",
    "\n",
    "tf_train = pd.DataFrame(data=transformer.toarray(),\n",
    "                        index= docs_train.index,    # keeping original idices\n",
    "                        columns=features)           # feature names as columns\n",
    "tf_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>apr</th>\n",
       "      <th>articl</th>\n",
       "      <th>ask</th>\n",
       "      <th>awai</th>\n",
       "      <th>believ</th>\n",
       "      <th>best</th>\n",
       "      <th>better</th>\n",
       "      <th>bike</th>\n",
       "      <th>call</th>\n",
       "      <th>case</th>\n",
       "      <th>...</th>\n",
       "      <th>try</th>\n",
       "      <th>univers</th>\n",
       "      <th>us</th>\n",
       "      <th>wai</th>\n",
       "      <th>want</th>\n",
       "      <th>word</th>\n",
       "      <th>work</th>\n",
       "      <th>world</th>\n",
       "      <th>write</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9319</th>\n",
       "      <td>0.185693</td>\n",
       "      <td>0.294361</td>\n",
       "      <td>0.267365</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.259840</td>\n",
       "      <td>0.421339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7883</th>\n",
       "      <td>0.094486</td>\n",
       "      <td>0.074889</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.282467</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6290</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.445315</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.271196</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>947</th>\n",
       "      <td>0.050681</td>\n",
       "      <td>0.040170</td>\n",
       "      <td>0.145945</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.035459</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11242</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.243442</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 91 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            apr    articl       ask  awai  believ  best  better  bike  call  \\\n",
       "9319   0.185693  0.294361  0.267365   0.0     0.0   0.0     0.0   0.0   0.0   \n",
       "7883   0.094486  0.074889  0.000000   0.0     0.0   0.0     0.0   0.0   0.0   \n",
       "6290   0.000000  0.000000  0.000000   0.0     0.0   0.0     0.0   0.0   0.0   \n",
       "947    0.050681  0.040170  0.145945   0.0     0.0   0.0     0.0   0.0   0.0   \n",
       "11242  0.000000  0.000000  0.000000   0.0     0.0   0.0     0.0   0.0   0.0   \n",
       "\n",
       "       case  ...  try  univers        us       wai  want  word  work  world  \\\n",
       "9319    0.0  ...  0.0      0.0  0.000000  0.000000   0.0   0.0   0.0    0.0   \n",
       "7883    0.0  ...  0.0      0.0  0.282467  0.000000   0.0   0.0   0.0    0.0   \n",
       "6290    0.0  ...  0.0      0.0  0.000000  0.445315   0.0   0.0   0.0    0.0   \n",
       "947     0.0  ...  0.0      0.0  0.000000  0.000000   0.0   0.0   0.0    0.0   \n",
       "11242   0.0  ...  0.0      0.0  0.000000  0.243442   0.0   0.0   0.0    0.0   \n",
       "\n",
       "          write      year  \n",
       "9319   0.259840  0.421339  \n",
       "7883   0.000000  0.000000  \n",
       "6290   0.271196  0.000000  \n",
       "947    0.035459  0.000000  \n",
       "11242  0.000000  0.000000  \n",
       "\n",
       "[5 rows x 91 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Transforming test data according to the vector fitted to the !training data!\n",
    "transformer_test = fitted_vec.transform(docs_test)\n",
    "\n",
    "tf_test = pd.DataFrame(data=transformer_test.toarray(),\n",
    "                        index= docs_test.index,        # keeping original idices\n",
    "                        columns=features)              # feature names as columns\n",
    "tf_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part B) Naive Bayes\n",
    "\n",
    "\n",
    "*  **class sklearn.naive_bayes.MultinomialNB(*, alpha=1.0, fit_prior=True, class_prior=None)**\n",
    "    - Naive Bayes classifier for multinomial models\n",
    "    - The multinomial Naive Bayes classifier is suitable for classification with discrete features (e.g., word counts for text classification). The multinomial distribution normally requires integer feature counts. *However, in practice, fractional counts such as tf-idf may also work.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Naive Bayes Model\n",
    "clf = MultinomialNB()\n",
    "clf.fit(tf_train, y_train) #Model trained on training set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The prediction is derived from the test set. It is an array with the predicted targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([10, 15, 17, 15, 10, 15, 10, 10,  8,  8, 15, 15, 17, 15, 15, 10,  8,\n",
       "       10, 10, 10, 15, 15,  8,  8, 15,  8, 17, 10, 17, 10, 15, 15, 17, 15,\n",
       "        8,  8, 17,  8,  8,  8,  8, 17, 10, 15, 17, 15, 10, 17, 17, 15, 17,\n",
       "       17, 10, 10, 10, 10, 17,  8, 15,  8,  8, 10, 17, 17,  8, 15, 17, 15,\n",
       "       10,  8, 17, 10, 15,  8, 15, 10, 15,  8, 17, 10, 10,  8, 10, 10, 17,\n",
       "        8,  8,  8, 10,  8, 10, 10, 17, 10, 17, 15, 15, 15,  8, 17, 15, 17,\n",
       "       15, 15, 17,  8,  8, 15,  8, 10, 10, 15, 17, 15,  8, 10, 17,  8, 15,\n",
       "       15, 17, 17,  8, 10,  8, 17,  8, 10,  8,  8,  8, 10, 15, 17,  8, 17,\n",
       "       17, 17, 15,  8, 17,  8, 10, 15,  8,  8,  8,  8,  8,  8,  8, 15, 10,\n",
       "       10, 17, 17, 10, 10,  8, 10,  8, 17, 10, 17, 10, 10, 15, 10,  8, 15,\n",
       "       15, 15,  8,  8,  8, 10,  8, 15, 17, 15,  8, 10, 10, 17,  8,  8, 15,\n",
       "       17, 17, 17,  8, 17,  8, 17, 17,  8,  8,  8, 15,  8,  8, 10, 10, 17,\n",
       "        8,  8, 15, 10, 15, 10, 17,  8, 10, 15, 15, 17,  8,  8, 15,  8, 15,\n",
       "       15,  8, 15,  8,  8, 10, 10,  8, 17,  8,  8, 17,  8, 15, 15, 15,  8,\n",
       "       10, 17, 17,  8, 17, 10,  8, 15, 15, 17,  8, 17, 10, 10, 15, 17,  8,\n",
       "        8,  8, 10,  8,  8,  8, 15, 17, 10,  8,  8,  8, 15, 15, 17, 15,  8,\n",
       "       17, 17, 17, 15, 15, 15, 17, 10, 15, 17,  8, 10, 15, 10, 10, 15,  8,\n",
       "       17, 15, 10,  8, 17, 10,  8, 15, 15, 17, 17, 10,  8, 15, 10, 15, 17,\n",
       "        8, 10, 10, 15,  8,  8, 15,  8, 15,  8, 10,  8,  8, 10,  8,  8, 15,\n",
       "       10, 15, 17, 10, 15, 15, 10, 15, 15, 15, 17, 10, 10, 10, 15, 10, 15,\n",
       "        8, 10, 10,  8,  8,  8, 10, 10, 10, 10, 17, 17,  8, 17,  8, 15, 17,\n",
       "        8, 15, 10,  8, 17, 17, 10, 10, 15,  8, 17, 10, 17, 17, 15, 15, 10,\n",
       "       17,  8,  8, 10,  8,  8,  8, 15,  8,  8,  8, 10, 10,  8, 15, 10,  8,\n",
       "       15,  8, 10, 15,  8, 15,  8, 17, 15, 10, 17, 17, 10,  8,  8, 10,  8,\n",
       "       15, 10, 17, 17, 10, 17,  8, 15, 17, 10, 10, 15, 15, 10,  8, 15, 15,\n",
       "       15,  8, 17,  8, 10, 10, 15, 17, 10, 10, 17,  8, 17, 17, 10, 10, 17,\n",
       "       10, 15, 15, 17, 17,  8, 10, 15, 15, 17, 15, 15,  8, 15,  8, 15, 15,\n",
       "       10,  8, 10, 17, 10,  8,  8, 10, 15, 17, 10, 15, 10,  8],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating the predictions\n",
    "y_pred = clf.predict(tf_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluating the Model:\n",
    "\n",
    "* **score(self, X, y[, sample_weight]):** \n",
    "    - From MultinomialNB()\n",
    "    - Returns the mean accuracy on the given test data and labels\n",
    "    \n",
    "    \n",
    "*  **sklearn.metrics.accuracy_score(y_true, y_pred, *, normalize=True, sample_weight=None)**\n",
    "    - From sklearn.metrics\n",
    "    - Accuracy classification score.\n",
    "    - In multilabel classification, this function computes subset accuracy: the set of labels predicted for a sample must exactly match the corresponding set of labels in y_true.\n",
    "    \n",
    "\n",
    "*  **sklearn.metrics.classification_report(y_true, y_pred, *, labels=None, target_names=None, sample_weight=None, digits=2, output_dict=False, zero_division='warn')**\n",
    "    - From sklearn.metrics \n",
    "    - Build a text report showing the main classification metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naïve Bayes Score: 0.871822033898305\n",
      "Accuracy: 0.8393234672304439\n",
      "Classification Report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           8       0.82      0.87      0.84       134\n",
      "          10       0.90      0.89      0.89       118\n",
      "          15       0.79      0.87      0.83       106\n",
      "          17       0.85      0.73      0.79       115\n",
      "\n",
      "    accuracy                           0.84       473\n",
      "   macro avg       0.84      0.84      0.84       473\n",
      "weighted avg       0.84      0.84      0.84       473\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Evaluating the Model: Not so much difference between training accuracy and test accuracy\n",
    "\n",
    "print(\"Naïve Bayes Score: {0}\".format(clf.score(tf_train ,y_train))) # on train data \n",
    "\n",
    "print(\"Accuracy: {0}\".format(accuracy_score(y_test, y_pred))) # on test data\n",
    "\n",
    "print(\"Classification Report: \\n{0}\".format(classification_report(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part C) Random Forest\n",
    "\n",
    "* **class sklearn.pipeline.Pipeline(steps, *, memory=None, verbose=False)**\n",
    "     - The purpose of the pipeline is to assemble several steps that can be cross-validated together while setting different parameters. For this, it enables setting parameters of the various steps using their names and the parameter name separated by a ‘__’, as in the example below. A step’s estimator may be replaced entirely by setting the parameter with its name to another estimator, or a transformer removed by setting it to ‘passthrough’ or None.\n",
    "     \n",
    "     \n",
    "*  **class sklearn.ensemble.RandomForestClassifier(n_estimators=100, *, criterion='gini', max_depth=None, min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features='auto', max_leaf_nodes=None, min_impurity_decrease=0.0, min_impurity_split=None, bootstrap=True, oob_score=False, n_jobs=None, random_state=None, verbose=0, warm_start=False, class_weight=None, ccp_alpha=0.0, max_samples=None)**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We didn't define any parameters for the Random Forest other than the **random state**.\n",
    "  \n",
    "  * Controls both the randomness of the bootstrapping of the samples used when building trees (if bootstrap=True) and the sampling of the features to consider when looking for the best split at each node (if max_features < n_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('tfidf',\n",
       "                 TfidfVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.float64'>,\n",
       "                                 encoding='utf-8', input='content',\n",
       "                                 lowercase=True, max_df=0.7, max_features=None,\n",
       "                                 min_df=0.1, ngram_range=(1, 1), norm='l2',\n",
       "                                 preprocessor=None, smooth_idf=True,\n",
       "                                 stop_words=None, strip_accents=None,\n",
       "                                 sublinear_tf=False,\n",
       "                                 token_pattern...\n",
       "                 RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n",
       "                                        class_weight=None, criterion='gini',\n",
       "                                        max_depth=None, max_features='auto',\n",
       "                                        max_leaf_nodes=None, max_samples=None,\n",
       "                                        min_impurity_decrease=0.0,\n",
       "                                        min_impurity_split=None,\n",
       "                                        min_samples_leaf=1, min_samples_split=2,\n",
       "                                        min_weight_fraction_leaf=0.0,\n",
       "                                        n_estimators=100, n_jobs=None,\n",
       "                                        oob_score=False, random_state=42,\n",
       "                                        verbose=0, warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = Pipeline([('tfidf', TfidfVectorizer(max_df=0.7, min_df=0.1)),  # Transformation step 1 Tfidf\n",
    "               ('clf',RandomForestClassifier(random_state = 42)),]) # Transformation step 2 Random Forest\n",
    "\n",
    "\n",
    "rf.fit(docs_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([10, 15, 17, 15, 10, 10, 10,  8,  8,  8, 15, 15, 17, 15, 15, 10,  8,\n",
       "       10, 10, 10,  8, 15,  8,  8,  8,  8, 17, 10, 17, 10,  8, 15, 17, 15,\n",
       "        8,  8, 17, 10,  8, 17,  8, 17, 10, 17, 17, 15, 10, 17, 17, 15, 17,\n",
       "       17, 10, 10, 10, 10, 17,  8, 15,  8,  8, 10, 17, 17,  8, 15,  8, 15,\n",
       "       10,  8, 17, 10, 15,  8, 15, 10, 15,  8, 17, 10, 10, 17, 10, 10, 17,\n",
       "        8,  8,  8, 17,  8, 10, 10, 17, 10, 17, 15, 15, 15,  8, 17, 15, 17,\n",
       "       15, 15, 17,  8,  8,  8,  8, 10, 10, 15, 17, 15,  8, 10, 17,  8, 15,\n",
       "       15, 17, 17,  8, 10,  8, 17,  8, 10,  8,  8,  8, 10, 15, 17,  8, 17,\n",
       "       17, 17, 15,  8, 17,  8, 10, 15,  8, 10,  8,  8, 17,  8,  8, 15, 10,\n",
       "       10, 17, 17, 10, 10, 17, 10,  8, 17, 10, 17, 10, 10, 15, 15, 17, 15,\n",
       "       15, 15,  8,  8,  8, 10,  8, 15, 17, 15, 17,  8, 10, 17,  8,  8, 15,\n",
       "        8, 17, 17,  8, 17,  8, 17, 17,  8,  8,  8, 15,  8,  8, 10, 10, 17,\n",
       "        8,  8, 15, 10, 15, 10, 17,  8, 10, 15, 17, 17,  8,  8, 15,  8, 15,\n",
       "       15,  8, 15, 17,  8, 10, 10,  8, 17,  8,  8, 17, 10, 15, 15, 15,  8,\n",
       "       10, 17, 17,  8,  8, 15,  8,  8, 15,  8,  8, 17, 10, 10, 15, 17,  8,\n",
       "        8,  8, 10,  8,  8,  8, 15, 17, 10,  8, 10,  8, 15, 15, 17, 15,  8,\n",
       "       15, 17, 15, 17, 10, 15, 17, 10, 10, 17,  8, 10, 15, 10, 10, 15,  8,\n",
       "       17, 15, 10,  8, 17, 10,  8, 15, 15, 17, 17, 10,  8, 15, 10, 15, 17,\n",
       "       10, 10, 10, 15,  8,  8, 15,  8, 15, 10, 10,  8,  8, 10,  8, 17, 15,\n",
       "       10, 15,  8, 10, 17, 15, 10, 15,  8, 17, 17, 10, 10, 10, 15, 10, 15,\n",
       "        8, 10, 10,  8,  8,  8, 10, 10, 10, 10, 17, 17,  8, 15,  8, 15, 17,\n",
       "        8, 15, 10,  8, 17, 17, 10, 10, 15,  8, 17, 10, 17, 17, 10, 15, 10,\n",
       "       17,  8,  8, 10, 17, 10,  8, 15,  8,  8, 15, 10, 10, 10, 15, 10,  8,\n",
       "       15, 17, 10, 17,  8, 15,  8, 17, 15, 10, 17, 17, 10, 17,  8, 10,  8,\n",
       "       15, 10, 17, 17, 10, 17,  8, 15, 10, 10, 10, 15, 15, 10, 17, 15, 15,\n",
       "       15,  8, 15,  8, 10, 10, 15, 17, 15, 10, 17, 17, 17, 17, 10, 10, 17,\n",
       "        8, 15, 15, 17, 17,  8, 10, 15, 15, 17, 15, 15,  8, 15,  8, 15, 15,\n",
       "       10, 17,  8, 17, 10, 17,  8, 10, 15,  8, 10, 17, 10,  8],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating the predictions\n",
    "y_pred_rf = rf.predict(docs_test) # not to tf_test because the pipeline already applies tf-idf\n",
    "y_pred_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Score: 0.9936440677966102\n",
      "Accuracy: 0.864693446088795\n",
      "Classification Report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           8       0.88      0.87      0.88       134\n",
      "          10       0.85      0.88      0.87       118\n",
      "          15       0.83      0.84      0.84       106\n",
      "          17       0.89      0.86      0.88       115\n",
      "\n",
      "    accuracy                           0.86       473\n",
      "   macro avg       0.86      0.86      0.86       473\n",
      "weighted avg       0.87      0.86      0.86       473\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Evaluating the Model: Overall higher numbers than Naïve Bayes\n",
    "\n",
    "print(\"Random Forest Score: {0}\".format(rf.score(docs_train ,y_train))) # on train data \n",
    "\n",
    "print(\"Accuracy: {0}\".format(accuracy_score(y_test, y_pred_rf))) # on test data\n",
    "\n",
    "print(\"Classification Report: \\n{0}\".format(classification_report(y_test, y_pred_rf)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part D) Grid Search\n",
    "\n",
    "*  **class sklearn.model_selection.GridSearchCV(estimator, param_grid, *, scoring=None, n_jobs=None, iid='deprecated', refit=True, cv=None, verbose=0, pre_dispatch='2*n_jobs', error_score=nan, return_train_score=False)**\n",
    "    - Exhaustive search over specified parameter values for an estimator.\n",
    "    - GridSearchCV implements a “fit” and a “score” method. It also implements “predict”, “predict_proba”, “decision_function”, “transform” and “inverse_transform” if they are implemented in the estimator used.\n",
    "\n",
    "    - The parameters of the estimator used to apply these methods are optimized by cross-validated grid-search over a parameter grid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score=nan,\n",
       "             estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n",
       "                                              class_weight=None,\n",
       "                                              criterion='gini', max_depth=None,\n",
       "                                              max_features='auto',\n",
       "                                              max_leaf_nodes=None,\n",
       "                                              max_samples=None,\n",
       "                                              min_impurity_decrease=0.0,\n",
       "                                              min_impurity_split=None,\n",
       "                                              min_samples_leaf=1,\n",
       "                                              min_samples_split=2,\n",
       "                                              min_weight_fraction_leaf=0.0,\n",
       "                                              n_estimators=100, n_jobs=None,\n",
       "                                              oob_score=False, random_state=42,\n",
       "                                              verbose=0, warm_start=False),\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid={'min_samples_leaf': [3, 4, 5],\n",
       "                         'n_estimators': [10, 50, 100, 200, 300, 1000]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Parameters and values to be cross-validated\n",
    "param_grid = {'min_samples_leaf': [3, 4, 5], 'n_estimators': [10, 50, 100, 200,\n",
    "300, 1000]}\n",
    "\n",
    "# Setting the model again with the same random state\n",
    "rf = RandomForestClassifier(random_state = 42)\n",
    "\n",
    "#Cross validation on the RF model\n",
    "grid_search = GridSearchCV(estimator = rf,          # Model\n",
    "                           param_grid = param_grid, # Dictionary of parameters previously defined\n",
    "                           cv =10)                  # 10-Fold cross validation\n",
    "\n",
    "grid_search.fit(tf_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'min_samples_leaf': 4, 'n_estimators': 300}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Parameters that returned the best RF performance\n",
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model using the best RF parameters\n",
    "best_rf = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([10, 15, 17, 15, 10, 10, 10, 10,  8,  8, 17, 15, 17, 15, 15, 10,  8,\n",
       "       10, 10, 10, 10, 15,  8,  8, 10,  8, 17, 10, 17, 10,  8, 15, 17, 15,\n",
       "        8,  8, 17, 10,  8, 17,  8, 17, 10, 17, 17, 15, 10, 17, 17, 15, 17,\n",
       "       17, 10, 10, 10, 10, 17,  8, 15,  8,  8, 10, 17, 17,  8, 15,  8, 15,\n",
       "       10,  8, 17, 10, 15,  8, 15, 10, 15,  8, 17, 10, 10, 17, 10, 10, 17,\n",
       "        8,  8,  8, 17,  8, 10, 10, 17, 10, 17, 15, 15, 15, 17, 17, 15, 17,\n",
       "       15, 15, 17,  8,  8, 10,  8, 10, 10, 15, 17, 15,  8, 10, 17,  8, 15,\n",
       "       15, 17, 17,  8, 10,  8, 17,  8, 10,  8,  8,  8, 10, 15, 17,  8, 17,\n",
       "       17, 17, 15,  8, 17,  8, 10, 15,  8, 10,  8,  8, 17,  8,  8, 15, 10,\n",
       "       10, 17, 15, 10, 10, 10, 10,  8, 17, 10, 17, 10, 10, 15, 17, 17, 15,\n",
       "       15, 15,  8,  8,  8, 10,  8, 15, 17, 15, 17,  8, 10, 17,  8,  8, 15,\n",
       "       17, 17, 17,  8, 17,  8, 17, 17,  8,  8,  8, 15,  8,  8, 10, 10, 17,\n",
       "        8,  8, 15, 10, 15, 10, 17,  8, 10, 15, 17, 17,  8,  8, 15,  8, 15,\n",
       "       15,  8, 15, 17,  8, 10, 10,  8, 17,  8,  8, 17, 10, 15, 15, 15,  8,\n",
       "       10, 17, 17,  8, 10, 17,  8, 10, 15,  8,  8, 17, 10, 10, 15, 17,  8,\n",
       "        8,  8, 10,  8,  8,  8, 15, 17, 10,  8, 10,  8, 15, 15, 17, 15,  8,\n",
       "       17, 17, 17, 15, 10, 15, 17, 10, 10, 17,  8, 10, 15, 10, 10, 15,  8,\n",
       "       17, 15, 10,  8, 17, 10,  8, 15, 15, 17, 17, 10,  8, 15, 10, 15, 17,\n",
       "       17, 10, 10, 15,  8,  8, 15,  8, 15, 10, 10,  8,  8, 10,  8, 17, 15,\n",
       "       10, 15, 17, 10, 17, 15, 10, 15, 10, 15, 17, 10, 10, 10, 15, 10, 15,\n",
       "        8, 10, 10,  8,  8,  8, 10, 10, 10, 10, 17, 17,  8, 10,  8, 15, 17,\n",
       "        8, 15, 10,  8, 17, 17, 10, 15, 15,  8, 17, 10, 17, 17, 10, 15, 10,\n",
       "       17,  8,  8, 10, 17, 15,  8, 15,  8,  8, 15, 10, 10, 10, 15, 10,  8,\n",
       "       15,  8, 10, 17,  8, 15,  8, 17, 15, 10, 17, 17, 10,  8,  8, 10,  8,\n",
       "       15, 10, 17, 17, 10, 17, 10, 15, 10, 10, 10, 15, 15, 10, 17, 15, 15,\n",
       "       15,  8, 17,  8, 10, 10, 15, 17, 15, 10, 17, 17, 17, 17, 10, 10, 17,\n",
       "       10, 15, 15, 17, 17,  8, 10, 15, 15, 17, 15, 15,  8, 15,  8, 15, 15,\n",
       "       10, 17, 17, 17, 10, 17,  8, 10, 15,  8, 10, 15, 10,  8],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Prediction using the best RF parameters\n",
    "y_pred_best_rf = best_rf.predict(tf_test)\n",
    "y_pred_best_rf "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Score: 0.9528601694915254\n",
      "Accuracy: 0.8752642706131079\n",
      "Classification Report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           8       0.95      0.87      0.91       134\n",
      "          10       0.85      0.93      0.89       118\n",
      "          15       0.84      0.84      0.84       106\n",
      "          17       0.86      0.86      0.86       115\n",
      "\n",
      "    accuracy                           0.88       473\n",
      "   macro avg       0.87      0.87      0.87       473\n",
      "weighted avg       0.88      0.88      0.88       473\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Evaluating the best RF Model: \n",
    "\n",
    "print(\"Random Forest Score: {0}\".format(best_rf.score(tf_train ,y_train))) # on train data \n",
    "\n",
    "print(\"Accuracy: {0}\".format(accuracy_score(y_test, y_pred_best_rf))) # on test data\n",
    "\n",
    "print(\"Classification Report: \\n{0}\".format(classification_report(y_test, y_pred_best_rf)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part E) Doc2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Data Representation => Define a function for that later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hell', 'met', 'visual', 'damag', 'indic', 'articl', 'apr', 'freenet', 'carleton', 'freenet', 'carleton', 'lloyd', 'carr', 'write', 'previou', 'articl', 'maven', 'mavenri', 'altcit', 'eskimo', 'com', 'norman', 'hamer', 'sai', 'end', 'replac', 'real', 'near', 'futur', 'better', 'wear', 'total', 'nondamag', 'face', 'dot', 'rate', 'cheapi', 'fit', 'wind', 'wear', 'shoei', 'lot', 'comfort', 'keep', 'wind', 'better', 'quieter', 'minor', 'damag', 'wear', 'drop', 'paint', 'chip', 'far', 'better', 'helmet', 'poorli', 'fit', 'scratch', 'bang', 'repair', 'plu', 'confid', 'protect', 'helmet', 'continu', 'actual', 'depress', 'actual', 'crack', 'magnifi', 'glass', 'consid', 'replac', 'good', 'advic', 'coupl', 'year', 'involv', 'low', 'speed', 'getoff', 'land', 'pavement', 'head', 'helmet', 'hit', 'pavement', 'clunk', 'leav', 'coupl', 'ding', 'chip', 'paint', 'point', 'impact', 'visibl', 'damag', 'call', 'helmet', 'manufactur', 'inquir', 'damag', 'said', 'wai', 'fiberglass', 'shell', 'work', 'delamin', 'crack', 'wai', 'fiberglass', 'serv', 'spread', 'forc', 'impact', 'wider', 'area', 'fiberglass', 'thing', 'crushabl', 'foam', 'liner', 'take', 'care', 'absorb', 'hopefulli', 'remain', 'impact', 'forc', 'told', 'second', 'stage', 'fiberglass', 'function', 'delamin', 'glass', 'resin', 'layer', 'occur', 'visibl', 'sign', 'insid', 'outsid', 'helmet', 'suggest', 'send', 'helmet', 'inspect', 'includ', 'rai', 'sent', 'helmet', 'letter', 'state', 'damag', 'compromis', 'abil', 'helmet', 'provid', 'maximum', 'protect', 'suspect', 'letter', 'elimin', 'abl', 'claim', 'prior', 'damag', 'helmet', 'event', 'sue', 'line', 'appear', 'helmet', 'integr', 'compromis', 'visibl', 'sign', 'wai', 'know', 'sure', 'send', 'inspect', 'note', 'helmet', 'manufactur', 'provid', 'inspect', 'servic', 'point', 'consid', 'purchas', 'lid', 'ken', 'franklin', 'heaven', 'peopl', 'wait', 'ama', 'better', 'ain', 'gwrra', 'laugh', 'sinner', 'saint', 'dod', 'sinner', 'lot', 'fun', 'know', 'good', 'die', 'young']\n"
     ]
    }
   ],
   "source": [
    "#Creation of corpus with gensim based on the !train data!\n",
    "corpus_gen_train = [doc.split() for doc in docs_train]\n",
    "\n",
    "#Inspecting the first entry\n",
    "print(corpus_gen_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.test.utils import common_texts, get_tmpfile\n",
    "path = get_tmpfile(\"doc2vec.model\")\n",
    "\n",
    "#Tagging Documents in !train data!\n",
    "documents_train = [TaggedDocument(doc, [i]) for i, doc in enumerate(corpus_gen_train)]\n",
    "\n",
    "#Embedding the documents\n",
    "model = Doc2Vec(documents_train,vector_size=100, min_count=566)  \n",
    "\n",
    "#Saving the model\n",
    "model.save(\"doc2vec.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.3963367e-03 -1.1893557e-02 -4.1268421e-03  3.7784905e-03\n",
      " -2.6656841e-03  4.0297455e-04  1.7651098e-03  7.9713657e-04\n",
      " -5.2125896e-03  2.5157901e-03  1.6305648e-03  6.6535627e-03\n",
      " -4.3060565e-03  5.2296822e-03  5.2355751e-03  4.3371031e-03\n",
      " -6.5067555e-03  1.1398351e-03  1.9095560e-04 -5.9094657e-03\n",
      " -4.6825251e-03 -5.9981886e-03 -4.4597592e-03  1.9871416e-03\n",
      "  5.6557120e-03 -6.0188505e-03 -6.9962889e-03  5.0287731e-03\n",
      " -5.8627115e-03 -7.6248759e-04  5.7236204e-04 -6.0463008e-03\n",
      " -2.0309682e-03  2.4674316e-03 -5.1684538e-03 -6.1786096e-03\n",
      "  5.2267876e-03  6.3080224e-03 -5.8443096e-05  5.9241918e-03\n",
      " -2.6286105e-03  5.9304468e-05 -8.9045864e-04  2.0529469e-03\n",
      " -1.4413423e-03  4.0938584e-03 -2.9342831e-05  4.2279954e-03\n",
      " -1.5303650e-03  1.5876426e-03  4.4546295e-03  1.8313506e-03\n",
      " -1.1952707e-03 -3.4350883e-03 -5.4390664e-04 -7.1052648e-04\n",
      " -2.9528686e-03 -3.2611995e-03 -2.0333936e-03  6.8580406e-03\n",
      " -1.6272789e-03  2.3015083e-03  3.4936448e-03 -1.3426557e-04\n",
      "  8.4517673e-03  2.2831061e-03 -2.1202760e-03  1.3697312e-03\n",
      "  8.7859988e-04 -1.4006585e-03  5.4137632e-03 -3.5066693e-03\n",
      " -2.1016644e-03 -1.4512658e-03  1.9034334e-03 -2.9344652e-03\n",
      "  1.9552470e-03 -1.0770024e-03  9.8029096e-03  1.0634608e-03\n",
      "  3.6652840e-03 -2.9876892e-04 -1.7697006e-03  8.4174733e-04\n",
      " -1.7255333e-03  7.7314262e-04  2.2144869e-03 -7.7697765e-03\n",
      " -8.3607179e-04 -4.5297788e-03  3.7524742e-03  2.2289744e-03\n",
      "  5.6251977e-03  8.6608483e-04 -9.3996420e-04 -1.3721726e-03\n",
      "  2.3830812e-03  2.2282358e-03 -4.9037957e-03  5.0524753e-03]\n"
     ]
    }
   ],
   "source": [
    "#Embedding for first document\n",
    "print(model.docvecs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4389</th>\n",
       "      <td>0.001396</td>\n",
       "      <td>-0.011894</td>\n",
       "      <td>-0.004127</td>\n",
       "      <td>0.003778</td>\n",
       "      <td>-0.002666</td>\n",
       "      <td>0.000403</td>\n",
       "      <td>0.001765</td>\n",
       "      <td>0.000797</td>\n",
       "      <td>-0.005213</td>\n",
       "      <td>0.002516</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003752</td>\n",
       "      <td>0.002229</td>\n",
       "      <td>0.005625</td>\n",
       "      <td>0.000866</td>\n",
       "      <td>-0.000940</td>\n",
       "      <td>-0.001372</td>\n",
       "      <td>0.002383</td>\n",
       "      <td>0.002228</td>\n",
       "      <td>-0.004904</td>\n",
       "      <td>0.005052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10868</th>\n",
       "      <td>-0.007760</td>\n",
       "      <td>-0.023065</td>\n",
       "      <td>0.002202</td>\n",
       "      <td>-0.000417</td>\n",
       "      <td>-0.010338</td>\n",
       "      <td>-0.005583</td>\n",
       "      <td>-0.002406</td>\n",
       "      <td>-0.018592</td>\n",
       "      <td>-0.011225</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004696</td>\n",
       "      <td>0.008462</td>\n",
       "      <td>0.007305</td>\n",
       "      <td>0.001682</td>\n",
       "      <td>-0.002286</td>\n",
       "      <td>-0.006217</td>\n",
       "      <td>0.000839</td>\n",
       "      <td>0.009481</td>\n",
       "      <td>-0.000881</td>\n",
       "      <td>-0.007416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3983</th>\n",
       "      <td>-0.007226</td>\n",
       "      <td>-0.021738</td>\n",
       "      <td>0.001348</td>\n",
       "      <td>0.002087</td>\n",
       "      <td>-0.002993</td>\n",
       "      <td>-0.004367</td>\n",
       "      <td>0.003740</td>\n",
       "      <td>-0.012082</td>\n",
       "      <td>-0.009280</td>\n",
       "      <td>-0.002963</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007613</td>\n",
       "      <td>0.003658</td>\n",
       "      <td>0.010864</td>\n",
       "      <td>-0.000443</td>\n",
       "      <td>-0.007417</td>\n",
       "      <td>-0.005375</td>\n",
       "      <td>0.005498</td>\n",
       "      <td>0.009349</td>\n",
       "      <td>-0.006156</td>\n",
       "      <td>0.001409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10962</th>\n",
       "      <td>-0.003423</td>\n",
       "      <td>-0.018520</td>\n",
       "      <td>-0.001797</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>-0.001290</td>\n",
       "      <td>-0.005034</td>\n",
       "      <td>0.004260</td>\n",
       "      <td>-0.006846</td>\n",
       "      <td>-0.016246</td>\n",
       "      <td>-0.004855</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006086</td>\n",
       "      <td>0.003639</td>\n",
       "      <td>0.008259</td>\n",
       "      <td>-0.004876</td>\n",
       "      <td>-0.007276</td>\n",
       "      <td>-0.000097</td>\n",
       "      <td>-0.000627</td>\n",
       "      <td>0.003411</td>\n",
       "      <td>-0.000969</td>\n",
       "      <td>-0.001017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5434</th>\n",
       "      <td>0.002350</td>\n",
       "      <td>-0.000236</td>\n",
       "      <td>-0.003939</td>\n",
       "      <td>0.003621</td>\n",
       "      <td>-0.002028</td>\n",
       "      <td>-0.002557</td>\n",
       "      <td>0.001541</td>\n",
       "      <td>-0.001977</td>\n",
       "      <td>0.001683</td>\n",
       "      <td>-0.002280</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004032</td>\n",
       "      <td>-0.002015</td>\n",
       "      <td>0.000988</td>\n",
       "      <td>0.003196</td>\n",
       "      <td>-0.002971</td>\n",
       "      <td>0.003155</td>\n",
       "      <td>-0.003567</td>\n",
       "      <td>-0.003108</td>\n",
       "      <td>-0.004312</td>\n",
       "      <td>-0.000213</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0         1         2         3         4         5         6   \\\n",
       "4389   0.001396 -0.011894 -0.004127  0.003778 -0.002666  0.000403  0.001765   \n",
       "10868 -0.007760 -0.023065  0.002202 -0.000417 -0.010338 -0.005583 -0.002406   \n",
       "3983  -0.007226 -0.021738  0.001348  0.002087 -0.002993 -0.004367  0.003740   \n",
       "10962 -0.003423 -0.018520 -0.001797  0.000049 -0.001290 -0.005034  0.004260   \n",
       "5434   0.002350 -0.000236 -0.003939  0.003621 -0.002028 -0.002557  0.001541   \n",
       "\n",
       "             7         8         9   ...        90        91        92  \\\n",
       "4389   0.000797 -0.005213  0.002516  ...  0.003752  0.002229  0.005625   \n",
       "10868 -0.018592 -0.011225  0.000046  ...  0.004696  0.008462  0.007305   \n",
       "3983  -0.012082 -0.009280 -0.002963  ...  0.007613  0.003658  0.010864   \n",
       "10962 -0.006846 -0.016246 -0.004855  ...  0.006086  0.003639  0.008259   \n",
       "5434  -0.001977  0.001683 -0.002280  ...  0.004032 -0.002015  0.000988   \n",
       "\n",
       "             93        94        95        96        97        98        99  \n",
       "4389   0.000866 -0.000940 -0.001372  0.002383  0.002228 -0.004904  0.005052  \n",
       "10868  0.001682 -0.002286 -0.006217  0.000839  0.009481 -0.000881 -0.007416  \n",
       "3983  -0.000443 -0.007417 -0.005375  0.005498  0.009349 -0.006156  0.001409  \n",
       "10962 -0.004876 -0.007276 -0.000097 -0.000627  0.003411 -0.000969 -0.001017  \n",
       "5434   0.003196 -0.002971  0.003155 -0.003567 -0.003108 -0.004312 -0.000213  \n",
       "\n",
       "[5 rows x 100 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Making a list of embeddings\n",
    "doc_list = [model.docvecs[i] for i in range(len(documents_train))]\n",
    "\n",
    "#DF of train data embeddings\n",
    "embeddings_train = pd.DataFrame(data = doc_list, index = docs_train.index) #Keeping the original index\n",
    "embeddings_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Data Representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['washington', 'beat', 'pitt', 'articl', 'kkq', 'acsu', 'buffalo', 'edu', 'vrw', 'ubvmsd', 'buffalo', 'edu', 'ralph', 'ambrosio', 'write', 'articl', 'apr', 'mprgate', 'mpr', 'tasallot', 'galaxi', 'mpr', 'mathew', 'tasalloti', 'write', 'penguin', 'patrick', 'win', 'cup', 'hardest', 'task', 'divis', 'sure', 'washington', 'definitli', 'throw', 'rench', 'penguin', 'plan', 'canuck', 'fan', 'think', 'chanc', 'year', 'like', 'washington', 'team', 'stop', 'penguin', 'win', 'stanlei', 'cup', 'impress', 'penguin', 'cap', 'number', 'season', 'mathew', 'tasalloti', 'mpr', 'teltech', 'vancouv', 'canada', 'cours', 'ask', 'interject', 'opinion', 'matter', 'concern', 'island', 'playoff', 'come', 'jet', 'year', 'capit', 'pen', 'number', 'game', 'playoff', 'john', 'horstmann']\n"
     ]
    }
   ],
   "source": [
    "#Creation of corpus with gensim based on the filtered df\n",
    "corpus_gen_test = [doc.split() for doc in docs_test]\n",
    "\n",
    "#Inspecting the first entry\n",
    "print(corpus_gen_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9319</th>\n",
       "      <td>-0.010788</td>\n",
       "      <td>-0.039692</td>\n",
       "      <td>0.002857</td>\n",
       "      <td>-0.000329</td>\n",
       "      <td>-0.006811</td>\n",
       "      <td>-0.008127</td>\n",
       "      <td>0.000173</td>\n",
       "      <td>-0.024935</td>\n",
       "      <td>-0.027606</td>\n",
       "      <td>-0.008040</td>\n",
       "      <td>...</td>\n",
       "      <td>0.016948</td>\n",
       "      <td>0.006384</td>\n",
       "      <td>0.018834</td>\n",
       "      <td>-0.006050</td>\n",
       "      <td>-0.012544</td>\n",
       "      <td>-0.007320</td>\n",
       "      <td>0.004845</td>\n",
       "      <td>0.013044</td>\n",
       "      <td>-0.002063</td>\n",
       "      <td>-0.004712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7883</th>\n",
       "      <td>-0.013020</td>\n",
       "      <td>-0.030208</td>\n",
       "      <td>-0.000214</td>\n",
       "      <td>-0.000492</td>\n",
       "      <td>-0.003337</td>\n",
       "      <td>-0.011706</td>\n",
       "      <td>0.001804</td>\n",
       "      <td>-0.016930</td>\n",
       "      <td>-0.019966</td>\n",
       "      <td>-0.010637</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009585</td>\n",
       "      <td>0.005783</td>\n",
       "      <td>0.008245</td>\n",
       "      <td>-0.007979</td>\n",
       "      <td>-0.016057</td>\n",
       "      <td>-0.009085</td>\n",
       "      <td>0.001901</td>\n",
       "      <td>0.003422</td>\n",
       "      <td>-0.011730</td>\n",
       "      <td>0.001219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6290</th>\n",
       "      <td>-0.013674</td>\n",
       "      <td>-0.051941</td>\n",
       "      <td>-0.000700</td>\n",
       "      <td>-0.001908</td>\n",
       "      <td>-0.005934</td>\n",
       "      <td>-0.009560</td>\n",
       "      <td>-0.003545</td>\n",
       "      <td>-0.027874</td>\n",
       "      <td>-0.024789</td>\n",
       "      <td>-0.010275</td>\n",
       "      <td>...</td>\n",
       "      <td>0.016992</td>\n",
       "      <td>0.006905</td>\n",
       "      <td>0.016308</td>\n",
       "      <td>-0.012216</td>\n",
       "      <td>-0.011112</td>\n",
       "      <td>-0.015300</td>\n",
       "      <td>0.001851</td>\n",
       "      <td>0.008579</td>\n",
       "      <td>-0.016443</td>\n",
       "      <td>-0.000266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>947</th>\n",
       "      <td>0.011609</td>\n",
       "      <td>-0.011745</td>\n",
       "      <td>-0.004681</td>\n",
       "      <td>-0.005554</td>\n",
       "      <td>0.001701</td>\n",
       "      <td>-0.010558</td>\n",
       "      <td>-0.006708</td>\n",
       "      <td>-0.017164</td>\n",
       "      <td>-0.003311</td>\n",
       "      <td>-0.014088</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000045</td>\n",
       "      <td>-0.004607</td>\n",
       "      <td>0.002184</td>\n",
       "      <td>-0.020403</td>\n",
       "      <td>0.009527</td>\n",
       "      <td>-0.012453</td>\n",
       "      <td>0.005042</td>\n",
       "      <td>-0.003774</td>\n",
       "      <td>-0.022598</td>\n",
       "      <td>-0.002325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11242</th>\n",
       "      <td>-0.004142</td>\n",
       "      <td>-0.022578</td>\n",
       "      <td>-0.003927</td>\n",
       "      <td>0.003747</td>\n",
       "      <td>-0.001252</td>\n",
       "      <td>-0.009714</td>\n",
       "      <td>-0.004644</td>\n",
       "      <td>-0.020473</td>\n",
       "      <td>-0.012297</td>\n",
       "      <td>-0.004288</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010973</td>\n",
       "      <td>0.009235</td>\n",
       "      <td>0.008934</td>\n",
       "      <td>-0.007847</td>\n",
       "      <td>0.000395</td>\n",
       "      <td>-0.005111</td>\n",
       "      <td>-0.000332</td>\n",
       "      <td>0.002556</td>\n",
       "      <td>-0.009619</td>\n",
       "      <td>-0.005941</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0         1         2         3         4         5         6   \\\n",
       "9319  -0.010788 -0.039692  0.002857 -0.000329 -0.006811 -0.008127  0.000173   \n",
       "7883  -0.013020 -0.030208 -0.000214 -0.000492 -0.003337 -0.011706  0.001804   \n",
       "6290  -0.013674 -0.051941 -0.000700 -0.001908 -0.005934 -0.009560 -0.003545   \n",
       "947    0.011609 -0.011745 -0.004681 -0.005554  0.001701 -0.010558 -0.006708   \n",
       "11242 -0.004142 -0.022578 -0.003927  0.003747 -0.001252 -0.009714 -0.004644   \n",
       "\n",
       "             7         8         9   ...        90        91        92  \\\n",
       "9319  -0.024935 -0.027606 -0.008040  ...  0.016948  0.006384  0.018834   \n",
       "7883  -0.016930 -0.019966 -0.010637  ...  0.009585  0.005783  0.008245   \n",
       "6290  -0.027874 -0.024789 -0.010275  ...  0.016992  0.006905  0.016308   \n",
       "947   -0.017164 -0.003311 -0.014088  ... -0.000045 -0.004607  0.002184   \n",
       "11242 -0.020473 -0.012297 -0.004288  ...  0.010973  0.009235  0.008934   \n",
       "\n",
       "             93        94        95        96        97        98        99  \n",
       "9319  -0.006050 -0.012544 -0.007320  0.004845  0.013044 -0.002063 -0.004712  \n",
       "7883  -0.007979 -0.016057 -0.009085  0.001901  0.003422 -0.011730  0.001219  \n",
       "6290  -0.012216 -0.011112 -0.015300  0.001851  0.008579 -0.016443 -0.000266  \n",
       "947   -0.020403  0.009527 -0.012453  0.005042 -0.003774 -0.022598 -0.002325  \n",
       "11242 -0.007847  0.000395 -0.005111 -0.000332  0.002556 -0.009619 -0.005941  \n",
       "\n",
       "[5 rows x 100 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Making a list of embeddings of inferred vectors based on the model trained on train data\n",
    "doc_list_test = [model.infer_vector(i) for i in corpus_gen_test]\n",
    "\n",
    "#DF of test data embeddings\n",
    "embeddings_test = pd.DataFrame(data = doc_list_test, index = docs_test.index) #Keeping the original index\n",
    "embeddings_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameter Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score=nan,\n",
       "             estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n",
       "                                              class_weight=None,\n",
       "                                              criterion='gini', max_depth=None,\n",
       "                                              max_features='auto',\n",
       "                                              max_leaf_nodes=None,\n",
       "                                              max_samples=None,\n",
       "                                              min_impurity_decrease=0.0,\n",
       "                                              min_impurity_split=None,\n",
       "                                              min_samples_leaf=1,\n",
       "                                              min_samples_split=2,\n",
       "                                              min_weight_fraction_leaf=0.0,\n",
       "                                              n_estimators=100, n_jobs=None,\n",
       "                                              oob_score=False, random_state=42,\n",
       "                                              verbose=0, warm_start=False),\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid={'min_samples_leaf': [3, 4, 5],\n",
       "                         'n_estimators': [10, 50, 100, 200, 300, 1000]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Parameters and values to be cross-validated\n",
    "param_grid = {'min_samples_leaf': [3, 4, 5], 'n_estimators': [10, 50, 100, 200,\n",
    "300, 1000]}\n",
    "\n",
    "# Setting the model again with the same random state\n",
    "rf = RandomForestClassifier(random_state = 42)\n",
    "\n",
    "#Cross validation on the RF model\n",
    "grid_search = GridSearchCV(estimator = rf,          # Model\n",
    "                           param_grid = param_grid, # Dictionary of parameters previously defined\n",
    "                           cv =10)                  # 10-Fold cross validation\n",
    "\n",
    "grid_search.fit(embeddings_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'min_samples_leaf': 5, 'n_estimators': 1000}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Parameters that returned the best RF performance\n",
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model using the best RF parameters\n",
    "best_rf = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([10, 15, 17, 15, 15, 10, 10, 15, 17, 10, 15, 17, 17, 15,  8, 10, 10,\n",
       "        8, 10, 15, 17, 10, 10, 10, 15, 10, 17, 15, 17, 15, 15, 10, 17, 15,\n",
       "       15, 10, 17, 15, 10, 10, 10, 17, 10, 17, 17, 15, 10, 17, 17, 15, 17,\n",
       "       17, 10, 10, 10, 10, 17, 10, 10, 17, 10, 10, 17, 17, 10, 15, 10, 15,\n",
       "       10, 10, 15, 10,  8, 17, 15, 17, 15, 10, 17, 10, 10, 10,  8, 10, 17,\n",
       "        8, 10, 10,  8, 10, 10, 10, 15, 10, 17, 15, 15, 15, 10, 17, 10, 15,\n",
       "       15, 17, 10, 15, 10, 17, 10, 10, 10, 10, 17, 15, 10, 10, 17,  8, 15,\n",
       "       15, 17, 17, 10, 17, 17, 17, 10, 10, 10, 17, 10, 10, 10, 17, 10, 17,\n",
       "       17, 10, 15, 10, 17, 15, 10, 15, 15, 15, 10, 15, 15,  8, 15,  8, 10,\n",
       "       17, 15, 17, 10, 10, 17, 10, 17, 10, 10, 17, 10, 10, 17,  8, 15, 15,\n",
       "       15, 15,  8,  8, 15, 10, 15,  8,  8,  8, 10, 10, 10, 10, 10, 10, 15,\n",
       "       17, 17, 17, 15, 17, 10, 17, 17, 10, 10,  8, 15, 10, 15, 10, 10, 17,\n",
       "       10, 10, 15, 10, 15, 10, 17, 15, 10, 15, 10, 10, 10, 10, 15, 17, 15,\n",
       "       15, 15, 15, 15, 17, 10, 10, 10, 17,  8, 10, 17,  8, 15, 15, 15, 10,\n",
       "       10, 10, 17, 15, 17, 17, 15, 15, 10, 10, 10, 17, 10, 10, 10, 17, 10,\n",
       "        8, 10, 10, 17, 15, 15, 15, 17, 17, 10, 10, 17, 15, 17, 17, 15, 10,\n",
       "       15, 10, 10, 15, 17, 17, 17, 10, 17, 17,  8, 10, 15, 10, 10, 15, 17,\n",
       "       10, 17, 10, 10, 17, 10, 17, 15, 15, 17, 17, 10,  8, 10, 15, 15,  8,\n",
       "       15,  8, 10, 15, 17,  8, 15,  8, 10, 10, 10, 17, 10, 17, 15, 17, 15,\n",
       "       10, 10, 17, 17, 17, 15, 10, 15,  8, 17, 17, 10, 10, 10, 15, 10, 15,\n",
       "       17, 10, 10, 10, 17, 10, 10, 10,  8, 17, 17, 17, 15, 17, 10, 15, 10,\n",
       "       17, 10, 10, 10, 17, 17, 10, 10, 15,  8, 17, 10, 17, 17, 15, 15,  8,\n",
       "       17,  8, 10, 10, 10,  8, 10, 15, 10, 17, 15, 10, 10, 10, 15, 10, 15,\n",
       "       15, 10, 10, 15, 10, 15, 10, 17, 15, 17, 17, 17,  8,  8, 17, 15,  8,\n",
       "       15, 10, 15, 10, 17, 17, 17, 15, 10, 10, 10, 15, 15, 10, 10, 15, 10,\n",
       "       15, 10, 17, 10, 10, 10, 17, 10, 15, 10, 17, 10, 17, 17, 10, 10, 10,\n",
       "       10, 10, 15, 17, 17, 17, 10, 15, 15, 17,  8, 15, 10, 10,  8, 15, 15,\n",
       "       15, 17, 15, 10, 10, 15, 17, 10, 15, 10, 17, 17, 10,  8],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Prediction using the best RF parameters\n",
    "y_pred_best_rf = best_rf.predict(embeddings_test)\n",
    "y_pred_best_rf "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Score: 0.9888771186440678\n",
      "Accuracy: 0.5391120507399577\n",
      "Classification Report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           8       0.51      0.14      0.22       134\n",
      "          10       0.45      0.73      0.55       118\n",
      "          15       0.61      0.69      0.65       106\n",
      "          17       0.62      0.67      0.64       115\n",
      "\n",
      "    accuracy                           0.54       473\n",
      "   macro avg       0.55      0.56      0.52       473\n",
      "weighted avg       0.54      0.54      0.50       473\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Evaluating the best RF Model: \n",
    "\n",
    "print(\"Random Forest Score: {0}\".format(best_rf.score(embeddings_train ,y_train))) # on train data \n",
    "\n",
    "print(\"Accuracy: {0}\".format(accuracy_score(y_test, y_pred_best_rf))) # on test data\n",
    "\n",
    "print(\"Classification Report: \\n{0}\".format(classification_report(y_test, y_pred_best_rf)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
